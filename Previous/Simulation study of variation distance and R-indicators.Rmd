---
title: "Simulation study of the variation distance and R-indicators"
author: "Rasmus Bordoy, Thomas Gerds, Nina Føns Johnsen, Sidsel Marie Bernt Jørgensen"
date: "2023-10-17"
output:   
  html_document:
    theme: sandstone
    toc: true
    code_folding: hide
    header-includes: \usepackage{matchcal}
---
```{r,include=FALSE}
library(data.table)
library(tidyverse)
library(glmnet)
```


<details>
<summary>
<font size= "4"> **Theoretical section** </font>
</summary>
<br>

<details>
<summary>
<font size= "3"> **Section 1 - Defining Variation Distance for Survey Response** </font>
</summary>
<br>
This section has of now only applicability to discrete factor covariates with no specific ordering. It will be of interest to extend the theory to include numerical covariates.

Consider a dataset with $K$ covariates and $N$ rows, where each row is denoted $X_i, i = 1, \ldots, K$. It is possible to fit a response model (f.x. logistic regression) where record $i$ has a response if $\pi_i = 1$, and $\pi_i = 0$ in the case of non-response. Fitting an MLE model leads to an expression of the type
$$
{P}_{\hat{\theta}}(\pi = 1 | X = \bf{x}),
$$
where $\bf{x}$ is a vector collection of covariates. In the case of only one covariate $\bf{x}$ is just a single level (not number since it is a factor covariate).



For covariate $k \in \{1,\ldots K\}$ the number of groups/levels for the given covariate is denoted as $g_k$. Wlog $K$ covariates where covariate $k$ has $g_k$ groups can be turned into a single covariate by considering all grouped interactions, and such a covariate would contain $G$ groups where $G$ is
$$
G= \prod_{k=1}^K g_k.
$$
The variation distance that will measure the variation throughout the response propensities of each group in $\{1,\ldots,G\}$ will measure the pairwise difference between groups and sum up through these and dividing by the number of groups. When counting pairs of $G$ groups, where the pairs are commutative, i.e. $\{k,l\} = \{l,k\}, k \neq l$, and pairing with itself is not possible i.e. $\{k,k\} = \emptyset$, then the number of pairwise combinations are 
$$
\text{Number of possible pairwise combinations} = \frac{(G-1) \times G}{2}.
$$

The single variation distance between group $k$ and $l$ is defined as 
$$
|P_{\hat{\theta}}(\pi = 1 | X = k) - P_{\hat{\theta}}(\pi = 1 | X = l)|.
$$
It is more convenient to use the shorthand notation 
$
P_{\hat{\theta}}(\pi = 1 | X = k) =: p_{\hat{\theta}}(k).
$

The total variation distance average for a single covariate with $G$ groups can be found as
$$
 \frac{2}{(G-1) \times G} \sum_{l=k+1}^G \sum_{k=1}^G |p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)|,
$$
since 

\begin{align}
& |p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)| \in [0,1] \\
\Rightarrow   \qquad  & \frac{2}{(G-1) \times G} \sum_{l=k+1}^G \sum_{k=1}^G |p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)| 
\in [0,1].
\end{align}

In terms of "representativity", this number is closer to zero if $|p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)|$ is small throughout the indices. If speaking of representativity as 1 being high representativity, then it would be more natural to consider

$$
\text{Total variation distance} = V_D :=1- \frac{2}{(G-1) \times G} \sum_{l=k+1}^G \sum_{k=1}^G |p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)|.
$$
The behaviour of the above definition of a total variation distance seems useful, but it seems necessary to add an indicator such that we are only counting probabilities with are non-degenerate. . Consider all the set of indices in $\{ 1 , \ldots , G\}$ where all response propensities are larger than zero, then this set becomes $S = \{ k \in \{ 1, \ldots , G \} : \hat{\theta}_k  \neq 0 \}$, then the dimension/cardinality of $S$ is $G_S$, i.e. $|S| = \# S = G_S$. Hence the following total variation distance becomes useful
$$
\tilde{V_D} :=1- \frac{2}{(G_S-1) \times G_S} \sum_{l=k+1}^{G_S} \sum_{k=1}^{G_S} 1_{\{p_{\hat{\theta}}(k)>0,p_{\hat{\theta}}(l)>0\}}|p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)|.
$$



Choosing $G_s$ can f.x. be done by studying the Lasso estimator.

The behaviour of the above definition of a total variation distance will be examined in the section called "simulation study". The next section presents another representativity measure using R-indicators.

</details>

<details>
<summary>
<font size= "3"> **Section 2 - Defining R-indicators for Survey Response** </font>
</summary>
<br>
The paper "Estimation of an indicator of the representativeness of survey response" Shlomo, Skinner and Schouten (2012) is the backbone for results in the paper "Theoretical Properties of Partial Indicators for Representative Response" Shlomo and Schouten (2013). These papers, and more, are written by a group collaboration named the RISQ project (Representativity Indicators for Survey Quality).


$\textbf{Definition of R-indicators}$

Let $U$ denote units in a population, and let $s$ denote units in a sample, where $U$ has $N$ records and $s$ has $n$ records. Let $\pi_i$ be the response indicator being $1$ if item $i$ has responded to a survey when chosen for the sample. The response propensity is the conditional expectation of $\pi_i$ given the auxiliary variable(s) $x_i$ of the vector/matrix $X$ 

$$
p_i := p(x_i) = E(\pi_i | x_i).
$$
We assume that the values $x_i$ are known for all units in the sample, both respondents and non-respondents, and potentially also for the whole population.

The definition of the R-indicator for the population is 
$$
R_p = 1- 2 S_p,
$$
where $S_p^2$ is estimated by
$$
\hat{S}_p^2 = \frac{1}{N-1}\sum_{i \in s} \omega_i \, ( \hat{p}(x_i) - \hat{\bar{p}}_U)^2,
$$
with $\omega_i$ being inclusion weights in terms of $s$ with respect to $U$, and $\hat{\bar{p}}_U = \frac{1}{N}\sum_{i \in s} \omega_i \, \hat{p} (x_i)$. In a random sample all the weights are equal.

"R-indicators provide a single value between zero and one that measures the
closeness to representative response. Representativity is defined in terms of the response
propensities of different sample units given their values on a specified set of auxiliary
variables. Response is said to be representative if all the response propensities in the
sample are equal (and none are equal to zero)" Shlomo and Schouten (2013)

$\textbf{Bias adjustment of R-indicator}$

Shlomo and Schouten (2013) and Shlomo, Skinner and Schouten (2012) propose bias adjustments of the R-indicator due to the sample size dependent bias. It is stated that when sample size decreases, then the bias increases.

The following measures are of relevance

\begin{align}
\bar{p}_U & = \frac{\sum_{i \in U} p_i}{N}, \\
\hat{\bar{p}}_U & = \frac{\sum_{i \in s} \omega_i \hat{p}_i}{N}, \\
\hat{p}_i & = g^{-1}(x_i^T \hat{\beta}) \,\, \, \text{where } g \text{ is the link function,} \\
\bar{p}_s & = \frac{\sum_{i \in s} \omega_i p_i}{N} .
\end{align}

A decomposition of $\hat{S}_p$ is presented. First $\hat{p}_i - \hat{\bar{p}_U}$ is rewritten by adding zero


\begin{align}
\hat{p}_i - \hat{\bar{p}_U} &= (\hat{p}_i - p_i) + (p_i-\bar{p}_U) + (\bar{p}_U - \bar{p}_s)+(\bar{p}_s - \hat{\bar{p}}_U).
\end{align}

A distinction is made between taking expectation to the sampling mechanism and response mechanism. When speaking of $p_i$ (not $\hat{p}_i$) the expectation is with respect to the response mechanism, i.e. $p_i = E_r(\pi_i | x_i)$. When taking expectations with respect to the sampling mechanism (the design) it is denoted by $E_s(\cdot)$.

We will use that

\begin{align}
E_r(\hat{p}_i)  &\approx p_i, \\
E_r(\hat{\bar{p}}_U) & \approx \bar{p}_s,
\end{align}

in order to obtain


\begin{align}

E_r\left[ \left( \hat{p}_i - \hat{\bar{p}}_U
\right)^2
\right] &= 
E_r\left[ \left((\hat{p}_i - p_i) + (p_i-\bar{p}_U) + (\bar{p}_U - \bar{p}_s)+(\bar{p}_s - \hat{\bar{p}}_U)\right)^2
\right] \\
&=
E_r\left[ (\hat{p}_i - p_i)^2 + (p_i-\bar{p}_U)^2 + (\bar{p}_U - \bar{p}_s)^2+(\bar{p}_s - \hat{\bar{p}}_U)^2\right]
+ 2E_r(\hat{p}_i-p_i)(\bar{p}_s-\bar{p}_U) + 2(p_i - \bar{p}_U)(\bar{p}_U - \bar{p}_s) \\
& \qquad \qquad \qquad + \underset{=0}{\underbrace{2 E_r(\hat{p}_i - p_i)(p_i - \bar{p}_U) + 2 E_r(\hat{p}_i-p_i)(\bar{p}_U - \bar{p}_s) + 2 E_r(p_i - \bar{p}_U)(\bar{p}_s - \hat{\bar{p}}_U) + 2 E_r(\bar{p}_U - \bar{p}_s)(\bar{p}_s-\hat{\bar{p}}_U)}} \\
&= E_r\left[ (\hat{p}_i - p_i)^2\right] +E_r\left[ (\bar{p}_s - \hat{\bar{p}}_U)^2\right] + (p_i-\bar{p}_U)^2 + (\bar{p}_U - \bar{p}_s)^2 \\
& \qquad \qquad + 2E_r(\hat{p}_i-p_i)(\bar{p}_s-\bar{p}_U) + 2(p_i - \bar{p}_U)(\bar{p}_U - \bar{p}_s) \\
&= 
Var_r(\hat{p}_i) + Var_r(\hat{\bar{p}}_U) +(p_i-\bar{p}_U)^2 + (\bar{p}_U - \bar{p}_s)^2\\
&  \qquad \qquad  - 2 Cov_r(\hat{p}_i,\hat{\bar{p}}_U)-2(p_i - \bar{p}_U)(\bar{p}_s - \bar{p}_U) \\

&= Var_r(\hat{p}_i - \hat{\bar{p}}_U) +(p_i-\bar{p}_U)^2 + (\bar{p}_U - \bar{p}_s)^2 - 2(p_i - \bar{p}_U)(\bar{p}_s - \bar{p}_U) .
\end{align}


This leads to the following approximation for 
$E_r(\hat{S}_p^2)$:

\begin{align}
E_r(\hat{S}_p^2) & \approx \frac{1}{N-1} \sum_{i \in s} \omega_i \left\{
Var_r(\hat{p}_i - \hat{\bar{p}}_U) +(p_i-\bar{p}_U)^2 + (\bar{p}_U - \bar{p}_s)^2 - 2(p_i - \bar{p}_U)(\bar{p}_s - \bar{p}_U) 
\right\} \\
&=
\frac{1}{N-1} \sum_{i \in s} \omega_i 
Var_r(\hat{p}_i - \hat{\bar{p}}_U) + \frac{1}{N-1} \sum_{i \in s} \omega_i  (p_i-\bar{p}_U)^2 \\
& \qquad \qquad
+\frac{N_{s}}{N-1}(\bar{p}_U - \bar{p}_s)^2 -2 (\bar{p}_s - \bar{p}_U)  \underset{\approx N\bar{p}_s - N_s \bar{p}_U}{\underbrace{\frac{\sum_{i \in s} \omega_i(p_i - \bar{p}_U)}{N-1}}}
\\
&

\approx 
\frac{1}{N-1}\left\{ 
\sum_{i \in s} \omega_i 
Var_r(\hat{p}_i - \hat{\bar{p}}_U) + \sum_{i \in s} \omega_i  (p_i-\bar{p}_U)^2

 +N_{s}(\bar{p}_U - \bar{p}_s)^2 -2 (\bar{p}_s - \bar{p}_U)(N\bar{p}_s - N_s \bar{p}_U)
\right\},

\end{align}


where $N_s = \sum_{i \in s} \omega_i$.

Taking expectation with respect to the sampling design  gives

\begin{align}
E_s E_r(\hat{S}_p^2) = S^2_P + A_1 +A_2,
\end{align}

where 

\begin{align}
A_1 &= E_s \left[
\frac{1}{N-1} \sum_{i \in s} \omega_i 
Var_r(\hat{p}_i - \hat{\bar{p}}_U)
\right], \\
A_2 &=
E_s \left[ \frac{1}{N-1} \left\{
N_{s}(\bar{p}_U - \bar{p}_s)^2 -2 (\bar{p}_s - \bar{p}_U)(N\bar{p}_s - N_s \bar{p}_U)
\right\}

\right].
\end{align}

$A_1$ is asymptotically equivalent to
$$
\lambda_1 = E_s \left[N^{-1}
\sum_{i \in s} \omega_i Var_r(\hat{p}_i)
\right].
$$

The term $A_2$ can be rewritten. Note
$$
N_{s}(\bar{p}_U - \bar{p}_s)^2 -2 (\bar{p}_s - \bar{p}_U)(N\bar{p}_s - N_s \bar{p}_U) = (N_{s}-2N)(\bar{p}_U - \bar{p}_s)^2 -2(N-N_s)  (\bar{p}_s - \bar{p}_U)\bar{p}_U.
$$


Asymptotically $A_2$ is equivalent to, when ignoring terms of lower order,
$$
\begin{align}
\lambda_2 & \approx - E_s \{ (\bar{p}_s - \bar{p}_U)^2\} + 2 \bar{p}_U E_s \{ (N^{-1} N_s -1)(\bar{p}_s - \bar{p}_U) \} \\
&= - Var_s ( \bar{p}_s) + 2 \bar{p}_U N^{-1} Cov_s (N_s , \bar{p}_s).
\end{align}
$$

This leads to the bias-adjusted R-indicator

$$
\tilde{S}_p^2 = \hat{S}^2_p - \hat{\lambda}_1-\hat{\lambda}_2,
$$

where $\hat{\lambda}_1$ and $\hat{\lambda}_2$ are estimators of $\lambda_1$ and $\lambda_2$ respectively. $\hat{\lambda_1}$ is
$$
\hat{\lambda_1} = \frac{1}{N} \sum_{i \in s} \omega_i \hat{V}_r(\hat{p}_i),
$$
where $\hat{V}_r(\hat{p}_i)$ is an estimator of ${Var}_r(\hat{p}_i)$. In the case of constant weights $\omega_i = N/n$, then $\hat{\lambda_1}$ is, according to Shlomo, Skinner and Schouten (2012)
$$
\hat{\lambda_1} = \frac{1}{n} \sum_{i \in s} \nabla h(\bf{x}_i^T \hat{\beta})^2 \bf{x}_i^T\left[ \sum_{ j \in s}
\nabla h(\bf{x}_j^T \hat{\beta})\bf{x}_j\bf{x}_j^T\right]^{-1}\bf{x}_i^T,
$$

where $\nabla h(\bf{x}_i^T \hat{\beta}) = \exp(\bf{x}_i^T\hat{\beta})/(1+\exp(\bf{x}_i^T\hat{\beta}))^2$, and $h$ being the link (inverse ??) function.

In terms of constant weights, the term $N_s$ is constant, then according to Shlomo, Skinner and Schouten (2012) $\hat{\lambda}_2$ becomes
$$
\hat{\lambda}_2 = -(n^{-1} - N^{-1})S_p^2.
$$
All in all this leads to the bias adjusted estimator of $S_p^2$ becoming
$$
\tilde{S}^2_p = \hat{S}^2_p - \hat{\lambda}_1- \hat{\lambda}_2 = (1+n^{-1} - N^{-1})\hat{S}_p^2 -  \frac{1}{n} \sum_{i \in s} \nabla h(\bf{x}_i^T \hat{\beta})^2 \bf{x}_i^T\left[ \sum_{ j \in s}
\nabla h(\bf{x}_j^T \hat{\beta})\bf{x}_j\bf{x}_j^T\right]^{-1}\bf{x}_i^T.
$$
</details>
</details>

<details>
<summary>
<font size= "4"> **Simulation study** </font>
</summary>
<br>

<details>
<summary>
<font size= "3"> **Generating data** </font>
</summary>
<br>

Using the distribution of the covariates from the data Life With a Heart Disease from 2020 by the Danish Heart Foundation, the distribution in terms of percentages looks as following when selecting the covariates Education, Heart Disease and Sex.

```{r}
men <- matrix(NA,nrow=6,ncol=6)
men[1,] <- c("","Education","","","","")
men[,1] <- c("","Heart Disease","HF","IHD","VHD","AF")
men[2,2:ncol(men)] <- c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")
men[3:nrow(men),2:ncol(men)] <- matrix(c(c(5.7,1.5,9.5,2.4,0.4),
                                         c(7.5,1.9,12,4.5,0.7),
                                         c(1.7,0.6,3,1.2,0.1),
                                         c(3.2,2,7.1,2.9,0.2)),ncol=5,nrow=4,byrow=TRUE)

men <- data.frame(men)
colnames(men) <- colnames(c(rep("",6)))
men[1,1] <- "Men"
knitr::kable(men[1:5,], format="markdown")

women <- matrix(NA,nrow=6,ncol=6)
women[1,] <- c("","Education","","","","")
women[,1] <- c("","Heart Disease","HF","IHD","VHD","AF")
women[2,2:ncol(women)] <- c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")
women[3:nrow(men),2:ncol(women)] <- matrix(c(c(3.4,0.3,2.7,1.1,0.2),
                                             c(4.1,0.2,3.9,1.9,0.2),
                                             c(1.7,0.1,1.4,0.8,0.1),
                                             c(3.4,0.4,3.7,2.2,0.1)),ncol=5,nrow=4,byrow=TRUE)

women <- data.frame(women)
colnames(women) <- colnames(c(rep("",6)))
women[1,1] <- "Women"
knitr::kable(women[1:6,], format="markdown")
```


```{r}
sum(as.numeric(unlist(as.vector(data.frame(men[-c(1,2),-1])))))+sum(as.numeric(unlist(as.vector(data.frame(women[-c(1,2),-1])))))
```
These sum to $100$.

Covariate are assigned to a dataframe that have the same distribution as above.
```{r}
#Number of rows
n <- 1000
```


```{r}
#Create a model matrix with 11 columns
df <- data.frame(matrix(0,nrow=n,ncol=11))
setDT(df)
#Assign column names
colnames(df) <- c("Male","Female","HF","IHD","VHD","AF","Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")

#Re structure the men and women dataframes in order to use these for create data with the same covariate distribution
men <- data.frame(men[-1,])
women <- data.frame(women[-1,])

#Find the indices as a function of 'n' such that the groups in data can be assigned as having the same distribution
ind <- 
  cumsum(c(round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Unknown education")])/100)))

#Assign 1's to the covariate columns of the model matrix
df[1:ind[1],c("Male","HF","Basic education")] <- 1
df[(ind[1]+1):ind[2],c("Male","HF","Postgraduate education")] <- 1
df[(ind[2]+1):ind[3],c("Male","HF","Secondary education")] <- 1
df[(ind[3]+1):ind[4],c("Male","HF","Tertiary education")] <- 1
df[(ind[4]+1):ind[5],c("Male","HF","Unknown education")] <- 1

df[(ind[5]+1):ind[6],c("Male","IHD","Basic education")] <- 1
df[(ind[6]+1):ind[7],c("Male","IHD","Postgraduate education")] <- 1
df[(ind[7]+1):ind[8],c("Male","IHD","Secondary education")] <- 1
df[(ind[8]+1):ind[9],c("Male","IHD","Tertiary education")] <- 1
df[(ind[9]+1):ind[10],c("Male","IHD","Unknown education")] <- 1

df[(ind[10]+1):ind[11],c("Male","VHD","Basic education")] <- 1
df[(ind[11]+1):ind[12],c("Male","VHD","Postgraduate education")] <- 1
df[(ind[12]+1):ind[13],c("Male","VHD","Secondary education")] <- 1
df[(ind[13]+1):ind[14],c("Male","VHD","Tertiary education")] <- 1
df[(ind[14]+1):ind[15],c("Male","VHD","Unknown education")] <- 1

df[(ind[15]+1):ind[16],c("Male","AF","Basic education")] <- 1
df[(ind[16]+1):ind[17],c("Male","AF","Postgraduate education")] <- 1
df[(ind[17]+1):ind[18],c("Male","AF","Secondary education")] <- 1
df[(ind[18]+1):ind[19],c("Male","AF","Tertiary education")] <- 1
df[(ind[19]+1):ind[20],c("Male","AF","Unknown education")] <- 1


df[(ind[20]+1):ind[21],c("Female","HF","Basic education")] <- 1
df[(ind[21]+1):ind[22],c("Female","HF","Postgraduate education")] <- 1
df[(ind[22]+1):ind[23],c("Female","HF","Secondary education")] <- 1
df[(ind[23]+1):ind[24],c("Female","HF","Tertiary education")] <- 1
df[(ind[24]+1):ind[25],c("Female","HF","Unknown education")] <- 1

df[(ind[25]+1):ind[26],c("Female","IHD","Basic education")] <- 1
df[(ind[26]+1):ind[27],c("Female","IHD","Postgraduate education")] <- 1
df[(ind[27]+1):ind[28],c("Female","IHD","Secondary education")] <- 1
df[(ind[28]+1):ind[29],c("Female","IHD","Tertiary education")] <- 1
df[(ind[29]+1):ind[30],c("Female","IHD","Unknown education")] <- 1

df[(ind[30]+1):ind[31],c("Female","VHD","Basic education")] <- 1
df[(ind[31]+1):ind[32],c("Female","VHD","Postgraduate education")] <- 1
df[(ind[32]+1):ind[33],c("Female","VHD","Secondary education")] <- 1
df[(ind[33]+1):ind[34],c("Female","VHD","Tertiary education")] <- 1
df[(ind[34]+1):ind[35],c("Female","VHD","Unknown education")] <- 1

df[(ind[35]+1):ind[36],c("Female","AF","Basic education")] <- 1
df[(ind[36]+1):ind[37],c("Female","AF","Postgraduate education")] <- 1
df[(ind[37]+1):ind[38],c("Female","AF","Secondary education")] <- 1
df[(ind[38]+1):ind[39],c("Female","AF","Tertiary education")] <- 1
df[(ind[39]+1):ind[40],c("Female","AF","Unknown education")] <- 1

knitr::kable(df[1:6,], format="markdown")
```

The count is (total $n=1000$)

```{r}
knitr::kable(colSums(df), format="markdown",col.names="n")
```


Each group is assigned a binary response simulated from the binomial distribution, and all the simulations come from a binomial distribution with **response probability equal to** $0.5$.
```{r}

df$Response <- 0
#df <- data.frame(df)

df[1:ind[1],"Response"] <- rbinom(ind[1],1,0.5)
df[(ind[1]+1):ind[2],"Response"] <- rbinom(ind[2]-ind[1],1,0.5)
df[(ind[2]+1):ind[3],"Response"] <- rbinom(ind[3]-ind[2],1,0.5)
df[(ind[3]+1):ind[4],"Response"] <- rbinom(ind[4]-ind[3],1,0.5)
df[(ind[4]+1):ind[5],"Response"] <- rbinom(ind[5]-ind[4],1,0.5)

df[(ind[5]+1):ind[6],"Response"] <- rbinom(ind[6]-ind[5],1,0.5)
df[(ind[6]+1):ind[7],"Response"] <- rbinom(ind[7]-ind[6],1,0.5)
df[(ind[7]+1):ind[8],"Response"] <- rbinom(ind[8]-ind[7],1,0.5)
df[(ind[8]+1):ind[9],"Response"] <- rbinom(ind[9]-ind[8],1,0.5)
df[(ind[9]+1):ind[10],"Response"] <- rbinom(ind[10]-ind[9],1,0.5)

df[(ind[10]+1):ind[11],"Response"] <- rbinom(ind[11]-ind[10],1,0.5)
df[(ind[11]+1):ind[12],"Response"] <- rbinom(ind[12]-ind[11],1,0.5)
df[(ind[12]+1):ind[13],"Response"] <- rbinom(ind[13]-ind[12],1,0.5)
df[(ind[13]+1):ind[14],"Response"] <- rbinom(ind[14]-ind[13],1,0.5)
df[(ind[14]+1):ind[15],"Response"] <- rbinom(ind[15]-ind[14],1,0.5)

df[(ind[15]+1):ind[16],"Response"] <- rbinom(ind[16]-ind[15],1,0.5)
df[(ind[16]+1):ind[17],"Response"] <- rbinom(ind[17]-ind[16],1,0.5)
df[(ind[17]+1):ind[18],"Response"] <- rbinom(ind[18]-ind[17],1,0.5)
df[(ind[18]+1):ind[19],"Response"] <- rbinom(ind[19]-ind[18],1,0.5)
df[(ind[19]+1):ind[20],"Response"] <- rbinom(ind[20]-ind[19],1,0.5)


df[(ind[20]+1):ind[21],"Response"] <- rbinom(ind[21]-ind[20],1,0.5)
df[(ind[21]+1):ind[22],"Response"] <- rbinom(ind[22]-ind[21],1,0.5)
df[(ind[22]+1):ind[23],"Response"] <- rbinom(ind[23]-ind[22],1,0.5)
df[(ind[23]+1):ind[24],"Response"] <- rbinom(ind[24]-ind[23],1,0.5)
df[(ind[24]+1):ind[25],"Response"] <- rbinom(ind[25]-ind[24],1,0.5)

df[(ind[25]+1):ind[26],"Response"] <- rbinom(ind[26]-ind[25],1,0.5)
df[(ind[26]+1):ind[27],"Response"] <- rbinom(ind[27]-ind[26],1,0.5)
df[(ind[27]+1):ind[28],"Response"] <- rbinom(ind[28]-ind[27],1,0.5)
df[(ind[28]+1):ind[29],"Response"] <- rbinom(ind[29]-ind[28],1,0.5)
df[(ind[29]+1):ind[30],"Response"] <- rbinom(ind[30]-ind[29],1,0.5)

df[(ind[30]+1):ind[31],"Response"] <- rbinom(ind[31]-ind[30],1,0.5)
df[(ind[31]+1):ind[32],"Response"] <- rbinom(ind[32]-ind[31],1,0.5)
df[(ind[32]+1):ind[33],"Response"] <- rbinom(ind[33]-ind[32],1,0.5)
df[(ind[33]+1):ind[34],"Response"] <- rbinom(ind[34]-ind[33],1,0.5)
df[(ind[34]+1):ind[35],"Response"] <- rbinom(ind[35]-ind[34],1,0.5)

df[(ind[35]+1):ind[36],"Response"] <- rbinom(ind[36]-ind[35],1,0.5)
df[(ind[36]+1):ind[37],"Response"] <- rbinom(ind[37]-ind[36],1,0.5)
df[(ind[37]+1):ind[38],"Response"] <- rbinom(ind[38]-ind[37],1,0.5)
df[(ind[38]+1):ind[39],"Response"] <- rbinom(ind[39]-ind[38],1,0.5)
df[(ind[39]+1):ind[40],"Response"] <- rbinom(ind[40]-ind[39],1,0.5)

p1 <-unlist(df[,sum(Response)/.N,by=c("Male","Female")][,3])
names(p1) <- c("Male","Female")

p2 <- unlist(df[,sum(Response)/.N,by=c("HF","IHD","VHD","AF")][,5])
names(p2) <- c("HF","IHD","VHD","AF")

p3 <- unlist(df[,sum(Response)/.N,by=c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")][,6])
names(p3) <- c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")

par(mfrow=c(1,3))
barplot(p1,ylim=c(0,1),ylab="Response %")
barplot(p2,ylim=c(0,1),ylab="Response %")
barplot(p3,ylim=c(0,1),ylab="Response %")
```

All the covariate combinations are then turned into a single covariate, and with $3$ groups with $2, 4$ and $5$ levels each leads to $2\cdot 4 \cdot 5=40$ groups in total.

```{r}
df$COV <- NA
df$COV[which(apply(df[,c("Male","HF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","HF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","IHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","VHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","AF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","AF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Unknown education"),collapse="_")



df$COV[which(apply(df[,c("Female","HF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","HF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","IHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","VHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","AF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","AF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Unknown education"),collapse="_")

knitr::kable(df[sample(n,6),], format="markdown")
```

The responses were simulated for each covariate combination, but due to the low count within some combinations the response simulations manage to have only $1$'s or $0$'s.

```{r}
A <- df[,round(sum(Response)/.N*100,1),by=COV]
names(A) <- c("COV","Response %")
r <- data.frame(cbind(c("...","..."),c("...","...")))
names(r) <- names(A)
setDT(r)
knitr::kable(rbind(head(A[order(A$`Response %`)]),
r,
tail(A[order(A$`Response %`)])), format="markdown")
```

</details>
<details>
<summary>
<font size= "3"> **Representativity results** </font>
</summary>
<br>

For the analysis of the representativity, the following measures will be computed:
\begin{align}
V_D & =1- \frac{2}{(G-1) \times G} \sum_{l=k+1}^G \sum_{k=1}^G |p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)|, \\
\tilde{V}_D & =1- \frac{2}{(G_S-1) \times G_S} \sum_{l=k+1}^{G_S} \sum_{k=1}^{G_S} 1_{\{p_{\hat{\theta}}(k)>0,p_{\hat{\theta}}(l)>0\}}|p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)| \\
\hat{R}_p & = 1- 2\hat{S}_p^2 = 1-2 \cdot \frac{1}{N-1}\sum_{i \in s} \omega_i \, ( \hat{p}(x_i) - \hat{\bar{p}}_U)^2, \\
\tilde{R}_p & = 1-2 \tilde{S}^2_p = 1-2 \left( \hat{S}^2_p - \hat{\lambda}_1- \hat{\lambda}_2 = (1+n^{-1} - N^{-1})\hat{S}_p^2 -  \frac{1}{n} \sum_{i \in s} \nabla h(\bf{x}_i^T \hat{\beta})^2 \bf{x}_i^T\left[ \sum_{ j \in s}
\nabla h(\bf{x}_j^T \hat{\beta})\bf{x}_j\bf{x}_j^T\right]^{-1}\bf{x}_i^T \right).
\end{align}
$\tilde{R}_p$ can only be computed using the link function $h$.

A GLM model is fitted with the explanatory variables being the covariate combinations.

```{r}
mod <- "glm"
if(mod == "glm"){m <- glm(Response~COV,data=df,family="binomial")}
if(mod == "cv.glmnet"){m <- cv.glmnet(y=df$Response,x=as.matrix(df[,-c("COV","Response")]),family="binomial",intercept=FALSE,type.measure = "deviance")}
```

No fitted response probabilities are $0$.
```{r}
options(scipen=999)
print(c("Minimum response probability"=min(fitted(m))))
```

This means that $V_D = \tilde{V}_D$.
```{r,message = FALSE}
if(class(m)[1] == "glm"){pred_mat <- data.frame(distinct(df[,c("COV")]))}
if(class(m)[1] == "cv.glmnet"){pred_mat <- as.matrix(distinct(df[,-c("COV","Response")]))}
#Total variation distance
A <- data.frame(COV=distinct(df[,-c("Response")])[,"COV"],P=predict(m,pred_mat,type="response"))
A <- A["P">0,]
G_s <- dim(A)[1]

for(i in 1:(dim(A)[1]-1)){
  if( i == 1){
    a <- abs(as.numeric(unlist(A[1,2])-unlist(A[-1,2])))
    names(a) <- paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+")
    A <- A[-1,]
    
  }else{
    a <- c(a,abs(as.numeric(unlist(A[1,2])-unlist(A[-1,2]))))
    names(a) <- c(names(a)[names(a) != ""],paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+"))
    A <- A[-1,]
  }
}

#R-indicator
if(class(m)[1] == "glm"){
  df_R <- cbind(df,P=predict(m,data.frame(df[,c("COV")]),type="response"))
  beta <- m$coefficients
  mod_mat <- model.matrix(m)
  lin_pred <- (model.matrix(m)) %*% beta
}

if(class(m)[1] == "cv.glmnet"){ 
  df_R <- cbind(df,P=predict(m,as.matrix(df[,-c("COV","Response")]),type="response",s=m$lambda.min))
  colnames(df_R)[ncol(df_R)] <- "P"
  beta <- coef(m,s=m$lambda.min)
  mod_mat <- as.matrix(df[,-c("COV","Response")])
  beta <- beta[,1][-c(which(names(beta[,1]) == "(Intercept)"))]
}

denom <- solve(sum(apply(mod_mat,1,FUN=function(x){as.numeric(exp(x %*% beta)/((1+exp(x %*% beta))^2))*( (x) %*% t(x))})))

S_2 <- (sum(((df_R$P - mean(df_R$Response))^2))/n)
data.frame(Model=paste(mod),
  V_d=round(1-sum(a)*2/((G_s-1)*G_s),3),
  R_tilde=round(1-2*sqrt(S_2-sum(apply(mod_mat,1,FUN=function(x){((exp(x %*% beta)/((1+exp(x %*% beta))^2))^2 %*% t(x)) %*% (as.numeric(denom)* matrix(x))}))/n),3),
  R_hat=round(1-2*sqrt(S_2),3))
```

In the setting with $n=1000$ and all response probabilities equal to $0.5$ and using GLM's, the representativity measures become:

```{r}
knitr::kable(data.frame(Model=paste(mod),
  V_d=round(1-sum(a)*2/((G_s-1)*G_s),3),
  R_tilde=round(1-2*sqrt(S_2-sum(apply(mod_mat,1,FUN=function(x){((exp(x %*% beta)/((1+exp(x %*% beta))^2))^2 %*% t(x)) %*% (as.numeric(denom)* matrix(x))}))/n),3),
  R_hat=round(1-2*sqrt(S_2),3)), caption="p=0.5",format="markdown")
```

The Lasso model makes subset selection, so the measure $V_d$ is calculated only for the groups which have non-zero coefficients.

```{r}
mod <- "cv.glmnet"
if(mod == "glm"){m <- glm(Response~COV,data=df,family="binomial")}
if(mod == "cv.glmnet"){m <- cv.glmnet(y=df$Response,x=as.matrix(df[,-c("COV","Response")]),family="binomial",intercept=FALSE,type.measure = "deviance")}


if(mod == "cv.glmnet"){
  sel_cov <- coef(m,s=m$lambda.1se)
  sel_cov <- sel_cov[,1][-c(which(names(sel_cov[,1]) == "(Intercept)"))]
  sel_cov <- sel_cov[sel_cov!= 0]
  sel_cov_names <- names(sel_cov)
}

if(class(m)[1] == "glm"){pred_mat <- data.frame(distinct(df[,c("COV")]))}

#Total variation distance
if(class(m)[1] == "glm"){
  
  A <- matrix(predict(m,pred_mat,type="response"))
  
  colnames(A) <- "P"
  
  G_s <- dim(A)[1]
  for(i in 1:(dim(A)[1]-1)){
    if( i == 1){
      
      a <- abs(as.numeric(unlist(A[1])-unlist(A[-1])))
      #names(a) <- paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+")
      A <- A[-1]
      
    }else{
      a <- c(a,abs(as.numeric(unlist(A[1])-unlist(A[-1]))))
      #names(a) <- c(names(a)[names(a) != ""],paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+"))
      A <- A[-1]
    }
  }
  1-sum(a)*2/((G_s-1)*G_s) 
}
if(class(m)[1] == "cv.glmnet")
{
  if(length(sel_cov)>0){
  pred_mat <- distinct(df[,..sel_cov_names])
  temp_df <- copy(distinct(df[,-..sel_cov_names][,-c("COV","Response")]))
  pred_mat <- cbind(pred_mat,apply(temp_df,c(1,2),function(x){x <- 0})[1:nrow(pred_mat),])
  pred_mat
  col_ind_pred_mat <- match(colnames(distinct(df[,-c("COV","Response")])), colnames(pred_mat))
  pred_mat <- as.matrix(pred_mat[,..col_ind_pred_mat])
  
  #A <- data.frame(COV=distinct(df[,-c("Response")])[,"COV"],P=predict(m,pred_mat,type="response"))
  A <- matrix(predict(m,pred_mat,type="response"))
  
  colnames(A) <- "P"
  
  G_s <- dim(A)[1]
  for(i in 1:(dim(A)[1]-1)){
    if( i == 1){
      
      a <- abs(as.numeric(unlist(A[1])-unlist(A[-1])))
      #names(a) <- paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+")
      A <- A[-1]
      
    }else{
      a <- c(a,abs(as.numeric(unlist(A[1])-unlist(A[-1]))))
      #names(a) <- c(names(a)[names(a) != ""],paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+"))
      A <- A[-1]
    }
  }
  1-sum(a)*2/((G_s-1)*G_s) 
}else{
  a <- 0
  G_s <- 2
}}
#R-indicator
if(class(m)[1] == "glm"){
  df_R <- cbind(df,P=predict(m,data.frame(df[,c("COV")]),type="response"))
  beta <- m$coefficients
  mod_mat <- model.matrix(m)
  lin_pred <- (model.matrix(m)) %*% beta
}

if(class(m)[1] == "cv.glmnet"){ 
  df_R <- cbind(df,P=predict(m,as.matrix(df[,-c("COV","Response")]),type="response",s=m$lambda.min))
  colnames(df_R)[ncol(df_R)] <- "P"
  beta <- coef(m,s=m$lambda.min)
  mod_mat <- as.matrix(df[,-c("COV","Response")])
  beta <- beta[,1][-c(which(names(beta[,1]) == "(Intercept)"))]
}

denom <- solve(sum(apply(mod_mat,1,FUN=function(x){as.numeric(exp(x %*% beta)/((1+exp(x %*% beta))^2))*( (x) %*% t(x))})))

S_2 <- (sum(((df_R$P - mean(df_R$Response))^2))/n)

knitr::kable(data.frame(Model=paste(mod),
  V_d=round(1-sum(a)*2/((G_s-1)*G_s),3),
  R_tilde=round(1-2*sqrt(S_2-sum(apply(mod_mat,1,FUN=function(x){((exp(x %*% beta)/((1+exp(x %*% beta))^2))^2 %*% t(x)) %*% (as.numeric(denom)* matrix(x))}))/n),3),
  R_hat=round(1-2*sqrt(S_2),3)), caption="p=0.5",format="markdown")
```

The Lasso can see that there is no need for coefficient apart from the intercept, and thus the representativity is $100\%$.


The tuning parameters in the above settings are: **sample size $n$, the 'true' response probabilities and also which model to use (GLM or Lasso)**. Creating a function from the above code lets us examine the representativity measures when changing the tuning parameters.

```{r}

representativity_simulation <- function(n,mod,p){
men <- matrix(NA,nrow=6,ncol=6)
men[1,] <- c("","Education","","","","")
men[,1] <- c("","Heart Disease","HF","IHD","VHD","AF")
men[2,2:ncol(men)] <- c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")
men[3:nrow(men),2:ncol(men)] <- matrix(c(c(5.7,1.5,9.5,2.4,0.4),
                                         c(7.5,1.9,12,4.5,0.7),
                                         c(1.7,0.6,3,1.2,0.1),
                                         c(3.2,2,7.1,2.9,0.2)),ncol=5,nrow=4,byrow=TRUE)

men <- data.frame(men)
colnames(men) <- colnames(c(rep("",6)))
men[1,1] <- "Men"

women <- matrix(NA,nrow=6,ncol=6)
women[1,] <- c("","Education","","","","")
women[,1] <- c("","Heart Disease","HF","IHD","VHD","AF")
women[2,2:ncol(women)] <- c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")
women[3:nrow(men),2:ncol(women)] <- matrix(c(c(3.4,0.3,2.7,1.1,0.2),
                                             c(4.1,0.2,3.9,1.9,0.2),
                                             c(1.7,0.1,1.4,0.8,0.1),
                                             c(3.4,0.4,3.7,2.2,0.1)),ncol=5,nrow=4,byrow=TRUE)

women <- data.frame(women)
colnames(women) <- colnames(c(rep("",6)))
women[1,1] <- "Women"


#n <- 5000

df <- data.frame(matrix(0,nrow=n,ncol=11))
setDT(df)
colnames(df) <- c("Male","Female","HF","IHD","VHD","AF","Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")

#Assign half of the records as male and female
#colnames(df) <- c("Sex","Heart Disease")
men <- data.frame(men[-1,])
women <- data.frame(women[-1,])

round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Basic education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Secondary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Basic education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Secondary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Basic education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Secondary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Basic education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Secondary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Basic education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Secondary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Basic education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Secondary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Basic education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Secondary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Basic education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Secondary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Unknown education")])/100)


ind <- 
  cumsum(c(round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Unknown education")])/100)))


df[1:ind[1],c("Male","HF","Basic education")] <- 1
df[(ind[1]+1):ind[2],c("Male","HF","Postgraduate education")] <- 1
df[(ind[2]+1):ind[3],c("Male","HF","Secondary education")] <- 1
df[(ind[3]+1):ind[4],c("Male","HF","Tertiary education")] <- 1
df[(ind[4]+1):ind[5],c("Male","HF","Unknown education")] <- 1

df[(ind[5]+1):ind[6],c("Male","IHD","Basic education")] <- 1
df[(ind[6]+1):ind[7],c("Male","IHD","Postgraduate education")] <- 1
df[(ind[7]+1):ind[8],c("Male","IHD","Secondary education")] <- 1
df[(ind[8]+1):ind[9],c("Male","IHD","Tertiary education")] <- 1
df[(ind[9]+1):ind[10],c("Male","IHD","Unknown education")] <- 1

df[(ind[10]+1):ind[11],c("Male","VHD","Basic education")] <- 1
df[(ind[11]+1):ind[12],c("Male","VHD","Postgraduate education")] <- 1
df[(ind[12]+1):ind[13],c("Male","VHD","Secondary education")] <- 1
df[(ind[13]+1):ind[14],c("Male","VHD","Tertiary education")] <- 1
df[(ind[14]+1):ind[15],c("Male","VHD","Unknown education")] <- 1

df[(ind[15]+1):ind[16],c("Male","AF","Basic education")] <- 1
df[(ind[16]+1):ind[17],c("Male","AF","Postgraduate education")] <- 1
df[(ind[17]+1):ind[18],c("Male","AF","Secondary education")] <- 1
df[(ind[18]+1):ind[19],c("Male","AF","Tertiary education")] <- 1
df[(ind[19]+1):ind[20],c("Male","AF","Unknown education")] <- 1


df[(ind[20]+1):ind[21],c("Female","HF","Basic education")] <- 1
df[(ind[21]+1):ind[22],c("Female","HF","Postgraduate education")] <- 1
df[(ind[22]+1):ind[23],c("Female","HF","Secondary education")] <- 1
df[(ind[23]+1):ind[24],c("Female","HF","Tertiary education")] <- 1
df[(ind[24]+1):ind[25],c("Female","HF","Unknown education")] <- 1

df[(ind[25]+1):ind[26],c("Female","IHD","Basic education")] <- 1
df[(ind[26]+1):ind[27],c("Female","IHD","Postgraduate education")] <- 1
df[(ind[27]+1):ind[28],c("Female","IHD","Secondary education")] <- 1
df[(ind[28]+1):ind[29],c("Female","IHD","Tertiary education")] <- 1
df[(ind[29]+1):ind[30],c("Female","IHD","Unknown education")] <- 1

df[(ind[30]+1):ind[31],c("Female","VHD","Basic education")] <- 1
df[(ind[31]+1):ind[32],c("Female","VHD","Postgraduate education")] <- 1
df[(ind[32]+1):ind[33],c("Female","VHD","Secondary education")] <- 1
df[(ind[33]+1):ind[34],c("Female","VHD","Tertiary education")] <- 1
df[(ind[34]+1):ind[35],c("Female","VHD","Unknown education")] <- 1

df[(ind[35]+1):ind[36],c("Female","AF","Basic education")] <- 1
df[(ind[36]+1):ind[37],c("Female","AF","Postgraduate education")] <- 1
df[(ind[37]+1):ind[38],c("Female","AF","Secondary education")] <- 1
df[(ind[38]+1):ind[39],c("Female","AF","Tertiary education")] <- 1
df[(ind[39]+1):ind[40],c("Female","AF","Unknown education")] <- 1



df$Response <- 0

#p <- c(rep(0.9,20),rep(0.5,20))
df[1:ind[1],"Response"] <- rbinom(ind[1],1,p[1]) #1
df[(ind[1]+1):ind[2],"Response"] <- rbinom(ind[2]-ind[1],1,p[2]) #2
df[(ind[2]+1):ind[3],"Response"] <- rbinom(ind[3]-ind[2],1,p[3]) #3
df[(ind[3]+1):ind[4],"Response"] <- rbinom(ind[4]-ind[3],1,p[4]) #4
df[(ind[4]+1):ind[5],"Response"] <- rbinom(ind[5]-ind[4],1,p[5]) #5
 
df[(ind[5]+1):ind[6],"Response"] <- rbinom(ind[6]-ind[5],1,p[6]) #6
df[(ind[6]+1):ind[7],"Response"] <- rbinom(ind[7]-ind[6],1,p[7]) #7
df[(ind[7]+1):ind[8],"Response"] <- rbinom(ind[8]-ind[7],1,p[8]) #8
df[(ind[8]+1):ind[9],"Response"] <- rbinom(ind[9]-ind[8],1,p[9]) #9
df[(ind[9]+1):ind[10],"Response"] <- rbinom(ind[10]-ind[9],1,p[10]) #10

df[(ind[10]+1):ind[11],"Response"] <- rbinom(ind[11]-ind[10],1,p[11]) #11
df[(ind[11]+1):ind[12],"Response"] <- rbinom(ind[12]-ind[11],1,p[12]) #12
df[(ind[12]+1):ind[13],"Response"] <- rbinom(ind[13]-ind[12],1,p[13]) #13
df[(ind[13]+1):ind[14],"Response"] <- rbinom(ind[14]-ind[13],1,p[14]) #14
df[(ind[14]+1):ind[15],"Response"] <- rbinom(ind[15]-ind[14],1,p[15]) #15

df[(ind[15]+1):ind[16],"Response"] <- rbinom(ind[16]-ind[15],1,p[16]) #16
df[(ind[16]+1):ind[17],"Response"] <- rbinom(ind[17]-ind[16],1,p[17]) #17
df[(ind[17]+1):ind[18],"Response"] <- rbinom(ind[18]-ind[17],1,p[18]) #18
df[(ind[18]+1):ind[19],"Response"] <- rbinom(ind[19]-ind[18],1,p[19]) #19
df[(ind[19]+1):ind[20],"Response"] <- rbinom(ind[20]-ind[19],1,p[20]) #20


df[(ind[20]+1):ind[21],"Response"] <- rbinom(ind[21]-ind[20],1,p[21]) #21
df[(ind[21]+1):ind[22],"Response"] <- rbinom(ind[22]-ind[21],1,p[22]) #22
df[(ind[22]+1):ind[23],"Response"] <- rbinom(ind[23]-ind[22],1,p[23]) #23
df[(ind[23]+1):ind[24],"Response"] <- rbinom(ind[24]-ind[23],1,p[24]) #24
df[(ind[24]+1):ind[25],"Response"] <- rbinom(ind[25]-ind[24],1,p[25]) #25

df[(ind[25]+1):ind[26],"Response"] <- rbinom(ind[26]-ind[25],1,p[26]) #26
df[(ind[26]+1):ind[27],"Response"] <- rbinom(ind[27]-ind[26],1,p[27]) #27
df[(ind[27]+1):ind[28],"Response"] <- rbinom(ind[28]-ind[27],1,p[28]) #28
df[(ind[28]+1):ind[29],"Response"] <- rbinom(ind[29]-ind[28],1,p[29]) #29
df[(ind[29]+1):ind[30],"Response"] <- rbinom(ind[30]-ind[29],1,p[30]) #30

df[(ind[30]+1):ind[31],"Response"] <- rbinom(ind[31]-ind[30],1,p[31]) #31
df[(ind[31]+1):ind[32],"Response"] <- rbinom(ind[32]-ind[31],1,p[32]) #32
df[(ind[32]+1):ind[33],"Response"] <- rbinom(ind[33]-ind[32],1,p[33]) #33
df[(ind[33]+1):ind[34],"Response"] <- rbinom(ind[34]-ind[33],1,p[34]) #34
df[(ind[34]+1):ind[35],"Response"] <- rbinom(ind[35]-ind[34],1,p[35]) #35

df[(ind[35]+1):ind[36],"Response"] <- rbinom(ind[36]-ind[35],1,p[36]) #36
df[(ind[36]+1):ind[37],"Response"] <- rbinom(ind[37]-ind[36],1,p[37]) #37
df[(ind[37]+1):ind[38],"Response"] <- rbinom(ind[38]-ind[37],1,p[38]) #38
df[(ind[38]+1):ind[39],"Response"] <- rbinom(ind[39]-ind[38],1,p[39]) #39
df[(ind[39]+1):ind[40],"Response"] <- rbinom(ind[40]-ind[39],1,p[40]) #40


df$COV <- NA
df$COV[which(apply(df[,c("Male","HF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","HF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","IHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","VHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","AF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","AF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Unknown education"),collapse="_")



df$COV[which(apply(df[,c("Female","HF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","HF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","IHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","VHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","AF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","AF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Unknown education"),collapse="_")


if(mod == "glm"){m <- glm(Response~COV,data=df,family="binomial")}
if(mod == "cv.glmnet"){m <- cv.glmnet(y=df$Response,x=as.matrix(df[,-c("COV","Response")]),family="binomial",intercept=FALSE,type.measure = "deviance")}


if(mod == "cv.glmnet"){
  sel_cov <- coef(m,s=m$lambda.1se)
  sel_cov <- sel_cov[,1][-c(which(names(sel_cov[,1]) == "(Intercept)"))]
  sel_cov <- sel_cov[sel_cov!= 0]
  sel_cov_names <- names(sel_cov)
}

if(class(m)[1] == "glm"){pred_mat <- data.frame(distinct(df[,c("COV")]))}

#Total variation distance
if(class(m)[1] == "glm"){
  
  A <- matrix(predict(m,pred_mat,type="response"))
  
  colnames(A) <- "P"
  
  G_s <- dim(A)[1]
  for(i in 1:(dim(A)[1]-1)){
    if( i == 1){
      
      a <- abs(as.numeric(unlist(A[1])-unlist(A[-1])))
      #names(a) <- paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+")
      A <- A[-1]
      
    }else{
      a <- c(a,abs(as.numeric(unlist(A[1])-unlist(A[-1]))))
      #names(a) <- c(names(a)[names(a) != ""],paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+"))
      A <- A[-1]
    }
  }
  1-sum(a)*2/((G_s-1)*G_s) 
}
if(class(m)[1] == "cv.glmnet")
{
  if(length(sel_cov)>0){
  pred_mat <- distinct(df[,..sel_cov_names])
  temp_df <- copy(distinct(df[,-..sel_cov_names][,-c("COV","Response")]))
  pred_mat <- cbind(pred_mat,apply(temp_df,c(1,2),function(x){x <- 0})[1:nrow(pred_mat),])
  pred_mat
  col_ind_pred_mat <- match(colnames(distinct(df[,-c("COV","Response")])), colnames(pred_mat))
  pred_mat <- as.matrix(pred_mat[,..col_ind_pred_mat])
  
  #A <- data.frame(COV=distinct(df[,-c("Response")])[,"COV"],P=predict(m,pred_mat,type="response"))
  A <- matrix(predict(m,pred_mat,type="response"))
  
  colnames(A) <- "P"
  
  G_s <- dim(A)[1]
  for(i in 1:(dim(A)[1]-1)){
    if( i == 1){
      
      a <- abs(as.numeric(unlist(A[1])-unlist(A[-1])))
      #names(a) <- paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+")
      A <- A[-1]
      
    }else{
      a <- c(a,abs(as.numeric(unlist(A[1])-unlist(A[-1]))))
      #names(a) <- c(names(a)[names(a) != ""],paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+"))
      A <- A[-1]
    }
  }
  1-sum(a)*2/((G_s-1)*G_s) 
}else{
  a <- 0
  G_s <- 2
}}

#R-indicator
if(class(m)[1] == "glm"){
  df_R <- cbind(df,P=predict(m,data.frame(df[,c("COV")]),type="response"))
  beta <- m$coefficients
  mod_mat <- model.matrix(m)
  lin_pred <- (model.matrix(m)) %*% beta
}

if(class(m)[1] == "cv.glmnet"){ 
  df_R <- cbind(df,P=predict(m,as.matrix(df[,-c("COV","Response")]),type="response",s=m$lambda.min))
  colnames(df_R)[ncol(df_R)] <- "P"
  beta <- coef(m,s=m$lambda.min)
  mod_mat <- as.matrix(df[,-c("COV","Response")])
  beta <- beta[,1][-c(which(names(beta[,1]) == "(Intercept)"))]
  }

denom <- solve(sum(apply(mod_mat,1,FUN=function(x){as.numeric(exp(x %*% beta)/((1+exp(x %*% beta))^2))*( (x) %*% t(x))})))

S_2 <- (sum(((df_R$P - mean(df_R$Response))^2))/n)
data.frame(n=n,
  Model=paste(mod),
  V_d=round(1-sum(a)*2/((G_s-1)*G_s),3),
  R_tilde=round(1-2*sqrt(S_2-sum(apply(mod_mat,1,FUN=function(x){((exp(x %*% beta)/((1+exp(x %*% beta))^2))^2 %*% t(x)) %*% (as.numeric(denom)* matrix(x))}))/n),3),
  R_hat=round(1-2*sqrt(S_2),3))


}
```

Changing only the sample size leads to
```{r}
knitr::kable(rbind(
representativity_simulation(n=1000,mod="glm",p=rep(0.5,40)),
representativity_simulation(n=1000,mod="cv.glmnet",p=rep(0.5,40)),
representativity_simulation(n=5000,mod="glm",p=rep(0.5,40)),
representativity_simulation(n=5000,mod="cv.glmnet",p=rep(0.5,40))),caption="p=0.5",format="markdown")
```


It is interesting to change all the response probabilities to become high or low. For the Lasso model, the R-indicators show incorrect results.
```{r}
knitr::kable(rbind(
representativity_simulation(n=1000,mod="glm",p=rep(0.25,40)),
representativity_simulation(n=1000,mod="cv.glmnet",p=rep(0.25,40)),
representativity_simulation(n=5000,mod="glm",p=rep(0.25,40)),
representativity_simulation(n=5000,mod="cv.glmnet",p=rep(0.25,40))),caption="p=0.25",format="markdown")

knitr::kable(rbind(
representativity_simulation(n=1000,mod="glm",p=rep(0.8,40)),
representativity_simulation(n=1000,mod="cv.glmnet",p=rep(0.8,40)),
representativity_simulation(n=5000,mod="glm",p=rep(0.8,40)),
representativity_simulation(n=5000,mod="cv.glmnet",p=rep(0.8,40))),caption="p=0.8",format="markdown")

```

Now we will vary the response probabilities for the 40 groups. 

The first $20$ groups are male, and then female. The first $5$ groups are male with Heart Failure. The subsequent are males with Ischemic heart disease and so on.

First a simulation is made when males have a true reponse probability of $30\%$ and female have a true response probability of $80\%$.


```{r}
knitr::kable(rbind(
representativity_simulation(n=1000,mod="glm",p=c(rep(0.3,20),rep(0.8,20))),
representativity_simulation(n=1000,mod="cv.glmnet",p=c(rep(0.3,20),rep(0.8,20))),
representativity_simulation(n=5000,mod="glm",p=c(rep(0.3,20),rep(0.8,20))),
representativity_simulation(n=5000,mod="cv.glmnet",p=c(rep(0.3,20),rep(0.8,20)))),caption="p(male)=0.3, p(female)=0.8",format="markdown")
```

Now a simulation study is made where males with heart diseases Heart Failure and Atrial Fibrillation have a response probability of $30\%$, males with Ischemic Heart Disease and Valvular Heart Disease have a response probability of $70\%$, whilst females have the same difference accors heart diseases but have a response probability that is $15\%$ higher.

```{r}
p <- c(rep(0.3,5),
rep(0.7,5),
rep(0.7,5),
rep(0.3,5),
rep(0.3+0.15,5),
rep(0.7+0.15,5),
rep(0.7+0.15,5),
rep(0.3+0.15,5))

knitr::kable(rbind(
representativity_simulation(n=1000,mod="glm",p=p),
representativity_simulation(n=1000,mod="cv.glmnet",p=p),
representativity_simulation(n=10000,mod="glm",p=p),
representativity_simulation(n=10000,mod="cv.glmnet",p=p)),caption="p(male,(HF,AF))=0.3, p(male,(IHD,VHD))=0.7, p(female,(HF,AF))=0.45, p(female,(IHD,VHD))=0.85,",format="markdown")
```


</details>
</details>