---
title: "Simulation study of the variation distance and R-indicators"
author: "Rasmus Bordoy, Thomas Gerds, Nina Føns Johnsen, Sidsel Marie Bernt Jørgensen"
date: "2023-10-17"
output:   
  html_document:
    theme: sandstone
    toc: true
    code_folding: hide
    header-includes: \usepackage{matchcal}
---
```{r,include=FALSE}
library(data.table)
library(tidyverse)
library(glmnet)
library(fastDummies)
```


<details>
<summary>
<font size= "4"> **Theoretical section** </font>
</summary>
<br>


#Section 1 - Defining Variation Distance for Survey Response


<details>
<summary>
<font size= "3"> **Section 1 - Defining Categorical Variation Distance for Survey Response** </font>
</summary>
<br>
This section has of now only applicability to discrete factor covariates with no specific ordering. It will be of interest to extend the theory to include numerical covariates.

Consider a dataset with $K$ covariates and $N$ rows, where each row is denoted $X_i, i = 1, \ldots, K$. It is possible to fit a response model (f.x. logistic regression) where record $i$ has a response if $\pi_i = 1$, and $\pi_i = 0$ in the case of non-response. Fitting an MLE model leads to an expression of the type
$$
{P}_{\hat{\theta}}(\pi = 1 | X = \bf{x}),
$$
where $\bf{x}$ is a vector collection of covariates. In the case of only one covariate $\bf{x}$ is just a single level (not number since it is a factor covariate).



For covariate $k \in \{1,\ldots K\}$ the number of groups/levels for the given covariate is denoted as $g_k$. Wlog $K$ covariates where covariate $k$ has $g_k$ groups can be turned into a single covariate by considering all grouped interactions, and such a covariate would contain $G$ groups where $G$ is
$$
G= \prod_{k=1}^K g_k.
$$
The variation distance that will measure the variation throughout the response propensities of each group in $\{1,\ldots,G\}$ will measure the pairwise difference between groups and sum up through these and dividing by the number of groups. When counting pairs of $G$ groups, where the pairs are commutative, i.e. $\{k,l\} = \{l,k\}, k \neq l$, and pairing with itself is not possible i.e. $\{k,k\} = \emptyset$, then the number of pairwise combinations are 
$$
\text{Number of possible pairwise combinations} = \frac{(G-1) \times G}{2}.
$$

The single variation distance between group $k$ and $l$ is defined as 
$$
|P_{\hat{\theta}}(\pi = 1 | X = k) - P_{\hat{\theta}}(\pi = 1 | X = l)|.
$$
It is more convenient to use the shorthand notation 
$
P_{\hat{\theta}}(\pi = 1 | X = k) =: p_{\hat{\theta}}(k).
$

The total variation distance average for a single covariate with $G$ groups can be found as
$$
 \frac{2}{(G-1) \times G} \sum_{l=k+1}^G \sum_{k=1}^G |p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)|,
$$
since 

\begin{align}
& |p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)| \in [0,1] \\
\Rightarrow   \qquad  & \frac{2}{(G-1) \times G} \sum_{l=k+1}^G \sum_{k=1}^G |p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)| 
\in [0,1].
\end{align}

In terms of "representativity", this number is closer to zero if $|p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)|$ is small throughout the indices. If speaking of representativity as 1 being high representativity, then it would be more natural to consider

$$
\text{Total variation distance} = V_D :=1- \frac{2}{(G-1) \times G} \sum_{l=k+1}^G \sum_{k=1}^G |p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)|.
$$
The behaviour of the above definition of a total variation distance seems useful, but it seems necessary to add an indicator such that we are only counting probabilities with are non-degenerate. . Consider all the set of indices in $\{ 1 , \ldots , G\}$ where all response propensities are larger than zero, then this set becomes $S = \{ k \in \{ 1, \ldots , G \} : \hat{\theta}_k  \neq 0 \}$, then the dimension/cardinality of $S$ is $G_S$, i.e. $|S| = \# S = G_S$. Hence the following total variation distance becomes useful
$$
\tilde{V_D} :=1- \frac{2}{(G_S-1) \times G_S} \sum_{l=k+1}^{G_S} \sum_{k=1}^{G_S} 1_{\{p_{\hat{\theta}}(k)>0,p_{\hat{\theta}}(l)>0\}}|p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)|.
$$



Choosing $G_s$ can f.x. be done by studying the Lasso estimator.

The behaviour of the above definition of a total variation distance will be examined in the section called "simulation study". The next section presents another representativity measure using R-indicators.

</details>

#Section 2 - Defining Variation Distance for Survey Response
<details>
<summary>
<font size= "3"> **Section 2 - Defining Ordinal Variation Distance for Survey Response** </font>
</summary>
<br>


If a categorical covariate can be translated into an ordinal covariate or a discrete one, where the assigned values are integers, then the variation distance can be calculated in a different manner than for categorical groups. When looping through, or summing through, a categorical covariate, then all permutations/interactions (saturated model) were of interest, but when a certain order exists in a covariate, then a different method of measuring distance is available, and should be used.


If a ordered covariate has values $$ s \in \left\{ 0,1,2, \ldots , t \right\} := \bar{T}, $$ then it is of interest to measure distances where the domain $\bar{T}$ is split up into subsets following a specific order. If $\bar{T} = \{1,2,3\}$, then the subsets of $\bar{T}$ are
$$
\begin{array}{l}
\{\{1\},\{2\},\{3\}\}, \\
\{\{1\},\{2,3\}\},\\
\{\{1,2\},\{3\}\}.
\end{array}
$$
This is different than usual permutations since the sets $\{\{2\},\{1,3\}\}$ and $\{\{\emptyset\},\{1,2,3\}\}$ don't occur, and the reason for this will be clear.

Denote the set of all non-void combinations of an ordered covariate with index-elements in $\bar{T}$ as $\mathscr{T}$.

Since the empty set is not considered, then there are $2^{t-1}-1$ elements in $\mathscr{T}$
$$
\# \mathscr{T} =\{ \text{No. of elements in }\mathscr{T} \} = 2^{t-1}-1.
$$
A way to find the number of combinations of elements with a chosen ordering is to consider the number of ways to set commas in between elements. Taking the same example as above, but writing 
$\bar{T} = \{1,2,3\} = 123$, then the subsets can be found as setting commas as
$$
\begin{array}{l}
1,23 \\
1,2,3 \\
12,3
\end{array}
$$
showing that there are 3 possible subsets. Allowing $\bar{T}$ to be arbitrarily large, then the number of commas can be found using binomial coefficients. 

The total number of group splits that are considered in $\mathscr{T}$ is
$$
\sum_{k=1}^{t-1} k {t -1 \choose k}.
$$
For each chosen element in $\mathscr{T}$, which all have between $2,\ldots , t-1$ group splits, then the maximum variation distance is sought for. The number of group splits for a chosen element $Z \in \mathscr{T}$ is denoted $\# Z$, and each group within the chosen element can be chosen as $z_i , i = 1,\ldots \# Z$. The variation distance is thus

$$
\sup_{Z \in \mathscr{T}} \sum_{i=1}^{\# Z } | P(\pi = 1 | X= z_i ) - P(\pi = 1 | X= z_{i-1} ) |.
$$
The representativity measure for integers/ordered categories thus becomes, since it must be between $ [0,1]$
$$
R_{\text{Ordinal}} = 1 - \sup_{Z \in \mathscr{T}} \frac{1}{(\#Z)}\sum_{i=1}^{\# Z } | P(\pi = 1 | X= z_i ) - P(\pi = 1 | X= z_{i-1} ) |.
$$

</details>

#Section 3 - Defining R-indicators for Survey Response



<details>
<summary>
<font size= "3"> **Section 3 - Defining R-indicators for Survey Response** </font>
</summary>
<br>
The paper "Estimation of an indicator of the representativeness of survey response" Shlomo, Skinner and Schouten (2012) is the backbone for results in the paper "Theoretical Properties of Partial Indicators for Representative Response" Shlomo and Schouten (2013). These papers, and more, are written by a group collaboration named the RISQ project (Representativity Indicators for Survey Quality).


$\textbf{Definition of R-indicators}$

Let $U$ denote units in a population, and let $s$ denote units in a sample, where $U$ has $N$ records and $s$ has $n$ records. Let $\pi_i$ be the response indicator being $1$ if item $i$ has responded to a survey when chosen for the sample. The response propensity is the conditional expectation of $\pi_i$ given the auxiliary variable(s) $x_i$ of the vector/matrix $X$ 

$$
p_i := p(x_i) = E(\pi_i | x_i).
$$
We assume that the values $x_i$ are known for all units in the sample, both respondents and non-respondents, and potentially also for the whole population.

The definition of the R-indicator for the population is 
$$
R_p = 1- 2 S_p,
$$
where $S_p^2$ is estimated by
$$
\hat{S}_p^2 = \frac{1}{N-1}\sum_{i \in s} \omega_i \, ( \hat{p}(x_i) - \hat{\bar{p}}_U)^2,
$$
with $\omega_i$ being inclusion weights in terms of $s$ with respect to $U$, and $\hat{\bar{p}}_U = \frac{1}{N}\sum_{i \in s} \omega_i \, \hat{p} (x_i)$. In a random sample all the weights are equal.

"R-indicators provide a single value between zero and one that measures the
closeness to representative response. Representativity is defined in terms of the response
propensities of different sample units given their values on a specified set of auxiliary
variables. Response is said to be representative if all the response propensities in the
sample are equal (and none are equal to zero)" Shlomo and Schouten (2013)

</details>
</details>



<details>
<summary>
<font size= "4"> **Simulation study** </font>
</summary>
<br>





<details>
<summary>
<font size= "3"> **Generating data** </font>
</summary>
<br>

#Generating data

Using the distribution of the covariates from the data Life With a Heart Disease from 2020 by the Danish Heart Foundation, the distribution in terms of percentages looks as following when selecting the covariates Education, Heart Disease and Sex.

```{r}
men <- matrix(NA,nrow=6,ncol=6)
men[1,] <- c("","Education","","","","")
men[,1] <- c("","Heart Disease","HF","IHD","VHD","AF")
men[2,2:ncol(men)] <- c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")
men[3:nrow(men),2:ncol(men)] <- matrix(c(c(5.7,1.5,9.5,2.4,0.4),
                                         c(7.5,1.9,12,4.5,0.7),
                                         c(1.7,0.6,3,1.2,0.1),
                                         c(3.2,2,7.1,2.9,0.2)),ncol=5,nrow=4,byrow=TRUE)

men <- data.frame(men)
colnames(men) <- colnames(c(rep("",6)))
men[1,1] <- "Men"
knitr::kable(men[1:5,], format="markdown")

women <- matrix(NA,nrow=6,ncol=6)
women[1,] <- c("","Education","","","","")
women[,1] <- c("","Heart Disease","HF","IHD","VHD","AF")
women[2,2:ncol(women)] <- c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")
women[3:nrow(men),2:ncol(women)] <- matrix(c(c(3.4,0.3,2.7,1.1,0.2),
                                             c(4.1,0.2,3.9,1.9,0.2),
                                             c(1.7,0.1,1.4,0.8,0.1),
                                             c(3.4,0.4,3.7,2.2,0.1)),ncol=5,nrow=4,byrow=TRUE)

women <- data.frame(women)
colnames(women) <- colnames(c(rep("",6)))
women[1,1] <- "Women"
knitr::kable(women[1:6,], format="markdown")
```


```{r}
sum(as.numeric(unlist(as.vector(data.frame(men[-c(1,2),-1])))))+sum(as.numeric(unlist(as.vector(data.frame(women[-c(1,2),-1])))))
```
These sum to $100$.

Covariate are assigned to a dataframe that have the same distribution as above.
```{r}
#Number of rows
n <- 1000
```


```{r}
#Create a model matrix with 11 columns
df <- data.frame(matrix(0,nrow=n,ncol=11))
setDT(df)
#Assign column names
colnames(df) <- c("Male","Female","HF","IHD","VHD","AF","Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")

#Re structure the men and women dataframes in order to use these for create data with the same covariate distribution
men <- data.frame(men[-1,])
women <- data.frame(women[-1,])

#Find the indices as a function of 'n' such that the groups in data can be assigned as having the same distribution
ind <- 
  cumsum(c(round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Unknown education")])/100)))

#Assign 1's to the covariate columns of the model matrix
df[1:ind[1],c("Male","HF","Basic education")] <- 1
df[(ind[1]+1):ind[2],c("Male","HF","Postgraduate education")] <- 1
df[(ind[2]+1):ind[3],c("Male","HF","Secondary education")] <- 1
df[(ind[3]+1):ind[4],c("Male","HF","Tertiary education")] <- 1
df[(ind[4]+1):ind[5],c("Male","HF","Unknown education")] <- 1

df[(ind[5]+1):ind[6],c("Male","IHD","Basic education")] <- 1
df[(ind[6]+1):ind[7],c("Male","IHD","Postgraduate education")] <- 1
df[(ind[7]+1):ind[8],c("Male","IHD","Secondary education")] <- 1
df[(ind[8]+1):ind[9],c("Male","IHD","Tertiary education")] <- 1
df[(ind[9]+1):ind[10],c("Male","IHD","Unknown education")] <- 1

df[(ind[10]+1):ind[11],c("Male","VHD","Basic education")] <- 1
df[(ind[11]+1):ind[12],c("Male","VHD","Postgraduate education")] <- 1
df[(ind[12]+1):ind[13],c("Male","VHD","Secondary education")] <- 1
df[(ind[13]+1):ind[14],c("Male","VHD","Tertiary education")] <- 1
df[(ind[14]+1):ind[15],c("Male","VHD","Unknown education")] <- 1

df[(ind[15]+1):ind[16],c("Male","AF","Basic education")] <- 1
df[(ind[16]+1):ind[17],c("Male","AF","Postgraduate education")] <- 1
df[(ind[17]+1):ind[18],c("Male","AF","Secondary education")] <- 1
df[(ind[18]+1):ind[19],c("Male","AF","Tertiary education")] <- 1
df[(ind[19]+1):ind[20],c("Male","AF","Unknown education")] <- 1


df[(ind[20]+1):ind[21],c("Female","HF","Basic education")] <- 1
df[(ind[21]+1):ind[22],c("Female","HF","Postgraduate education")] <- 1
df[(ind[22]+1):ind[23],c("Female","HF","Secondary education")] <- 1
df[(ind[23]+1):ind[24],c("Female","HF","Tertiary education")] <- 1
df[(ind[24]+1):ind[25],c("Female","HF","Unknown education")] <- 1

df[(ind[25]+1):ind[26],c("Female","IHD","Basic education")] <- 1
df[(ind[26]+1):ind[27],c("Female","IHD","Postgraduate education")] <- 1
df[(ind[27]+1):ind[28],c("Female","IHD","Secondary education")] <- 1
df[(ind[28]+1):ind[29],c("Female","IHD","Tertiary education")] <- 1
df[(ind[29]+1):ind[30],c("Female","IHD","Unknown education")] <- 1

df[(ind[30]+1):ind[31],c("Female","VHD","Basic education")] <- 1
df[(ind[31]+1):ind[32],c("Female","VHD","Postgraduate education")] <- 1
df[(ind[32]+1):ind[33],c("Female","VHD","Secondary education")] <- 1
df[(ind[33]+1):ind[34],c("Female","VHD","Tertiary education")] <- 1
df[(ind[34]+1):ind[35],c("Female","VHD","Unknown education")] <- 1

df[(ind[35]+1):ind[36],c("Female","AF","Basic education")] <- 1
df[(ind[36]+1):ind[37],c("Female","AF","Postgraduate education")] <- 1
df[(ind[37]+1):ind[38],c("Female","AF","Secondary education")] <- 1
df[(ind[38]+1):ind[39],c("Female","AF","Tertiary education")] <- 1
df[(ind[39]+1):ind[40],c("Female","AF","Unknown education")] <- 1

knitr::kable(df[1:6,], format="markdown")
```

The count is (total $n=1000$)

```{r}
knitr::kable(colSums(df), format="markdown",col.names="n")
```


Each group is assigned a binary response simulated from the binomial distribution, and all the simulations come from a binomial distribution with **response probability equal to** $0.5$.
```{r}

df$Response <- 0
#df <- data.frame(df)

df[1:ind[1],"Response"] <- rbinom(ind[1],1,0.5)
df[(ind[1]+1):ind[2],"Response"] <- rbinom(ind[2]-ind[1],1,0.5)
df[(ind[2]+1):ind[3],"Response"] <- rbinom(ind[3]-ind[2],1,0.5)
df[(ind[3]+1):ind[4],"Response"] <- rbinom(ind[4]-ind[3],1,0.5)
df[(ind[4]+1):ind[5],"Response"] <- rbinom(ind[5]-ind[4],1,0.5)

df[(ind[5]+1):ind[6],"Response"] <- rbinom(ind[6]-ind[5],1,0.5)
df[(ind[6]+1):ind[7],"Response"] <- rbinom(ind[7]-ind[6],1,0.5)
df[(ind[7]+1):ind[8],"Response"] <- rbinom(ind[8]-ind[7],1,0.5)
df[(ind[8]+1):ind[9],"Response"] <- rbinom(ind[9]-ind[8],1,0.5)
df[(ind[9]+1):ind[10],"Response"] <- rbinom(ind[10]-ind[9],1,0.5)

df[(ind[10]+1):ind[11],"Response"] <- rbinom(ind[11]-ind[10],1,0.5)
df[(ind[11]+1):ind[12],"Response"] <- rbinom(ind[12]-ind[11],1,0.5)
df[(ind[12]+1):ind[13],"Response"] <- rbinom(ind[13]-ind[12],1,0.5)
df[(ind[13]+1):ind[14],"Response"] <- rbinom(ind[14]-ind[13],1,0.5)
df[(ind[14]+1):ind[15],"Response"] <- rbinom(ind[15]-ind[14],1,0.5)

df[(ind[15]+1):ind[16],"Response"] <- rbinom(ind[16]-ind[15],1,0.5)
df[(ind[16]+1):ind[17],"Response"] <- rbinom(ind[17]-ind[16],1,0.5)
df[(ind[17]+1):ind[18],"Response"] <- rbinom(ind[18]-ind[17],1,0.5)
df[(ind[18]+1):ind[19],"Response"] <- rbinom(ind[19]-ind[18],1,0.5)
df[(ind[19]+1):ind[20],"Response"] <- rbinom(ind[20]-ind[19],1,0.5)


df[(ind[20]+1):ind[21],"Response"] <- rbinom(ind[21]-ind[20],1,0.5)
df[(ind[21]+1):ind[22],"Response"] <- rbinom(ind[22]-ind[21],1,0.5)
df[(ind[22]+1):ind[23],"Response"] <- rbinom(ind[23]-ind[22],1,0.5)
df[(ind[23]+1):ind[24],"Response"] <- rbinom(ind[24]-ind[23],1,0.5)
df[(ind[24]+1):ind[25],"Response"] <- rbinom(ind[25]-ind[24],1,0.5)

df[(ind[25]+1):ind[26],"Response"] <- rbinom(ind[26]-ind[25],1,0.5)
df[(ind[26]+1):ind[27],"Response"] <- rbinom(ind[27]-ind[26],1,0.5)
df[(ind[27]+1):ind[28],"Response"] <- rbinom(ind[28]-ind[27],1,0.5)
df[(ind[28]+1):ind[29],"Response"] <- rbinom(ind[29]-ind[28],1,0.5)
df[(ind[29]+1):ind[30],"Response"] <- rbinom(ind[30]-ind[29],1,0.5)

df[(ind[30]+1):ind[31],"Response"] <- rbinom(ind[31]-ind[30],1,0.5)
df[(ind[31]+1):ind[32],"Response"] <- rbinom(ind[32]-ind[31],1,0.5)
df[(ind[32]+1):ind[33],"Response"] <- rbinom(ind[33]-ind[32],1,0.5)
df[(ind[33]+1):ind[34],"Response"] <- rbinom(ind[34]-ind[33],1,0.5)
df[(ind[34]+1):ind[35],"Response"] <- rbinom(ind[35]-ind[34],1,0.5)

df[(ind[35]+1):ind[36],"Response"] <- rbinom(ind[36]-ind[35],1,0.5)
df[(ind[36]+1):ind[37],"Response"] <- rbinom(ind[37]-ind[36],1,0.5)
df[(ind[37]+1):ind[38],"Response"] <- rbinom(ind[38]-ind[37],1,0.5)
df[(ind[38]+1):ind[39],"Response"] <- rbinom(ind[39]-ind[38],1,0.5)
df[(ind[39]+1):ind[40],"Response"] <- rbinom(ind[40]-ind[39],1,0.5)

p1 <-unlist(df[,sum(Response)/.N,by=c("Male","Female")][,3])
names(p1) <- c("Male","Female")

p2 <- unlist(df[,sum(Response)/.N,by=c("HF","IHD","VHD","AF")][,5])
names(p2) <- c("HF","IHD","VHD","AF")

p3 <- unlist(df[,sum(Response)/.N,by=c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")][,6])
names(p3) <- c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")

par(mfrow=c(1,3))
barplot(p1,ylim=c(0,1),ylab="Response %")
barplot(p2,ylim=c(0,1),ylab="Response %")
barplot(p3,ylim=c(0,1),ylab="Response %")
```

All the covariate combinations are then turned into a single covariate, and with $3$ groups with $2, 4$ and $5$ levels each leads to $2\cdot 4 \cdot 5=40$ groups in total.

```{r}
df$COV <- NA
df$COV[which(apply(df[,c("Male","HF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","HF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","IHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","VHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","AF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","AF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Unknown education"),collapse="_")



df$COV[which(apply(df[,c("Female","HF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","HF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","IHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","VHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","AF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","AF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Unknown education"),collapse="_")

knitr::kable(df[sample(n,6),], format="markdown")
```

The responses were simulated for each covariate combination, but due to the low count within some combinations the response simulations manage to have only $1$'s or $0$'s.

```{r}
A <- df[,round(sum(Response)/.N*100,1),by=COV]
names(A) <- c("COV","Response %")
r <- data.frame(cbind(c("...","..."),c("...","...")))
names(r) <- names(A)
setDT(r)
knitr::kable(rbind(head(A[order(A$`Response %`)]),
r,
tail(A[order(A$`Response %`)])), format="markdown")
```




</details>
<details>
<summary>
<font size= "3"> **Representativity results** </font>
</summary>
<br>

#Representativity results

For the analysis of the representativity, the following measures will be computed:
\begin{align}
V_D & =1- \frac{2}{(G-1) \times G} \sum_{l=k+1}^G \sum_{k=1}^G |p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)|, \\
\tilde{V}_D & =1- \frac{2}{(G_S-1) \times G_S} \sum_{l=k+1}^{G_S} \sum_{k=1}^{G_S} 1_{\{p_{\hat{\theta}}(k)>0,p_{\hat{\theta}}(l)>0\}}|p_{\hat{\theta}}(k)-p_{\hat{\theta}}(l)| \\
\hat{R}_p & = 1- 2\hat{S}_p^2 = 1-2 \cdot \frac{1}{N-1}\sum_{i \in s} \omega_i \, ( \hat{p}(x_i) - \hat{\bar{p}}_U)^2, \\
\tilde{R}_p & = 1-2 \tilde{S}^2_p = 1-2 \left( \hat{S}^2_p - \hat{\lambda}_1- \hat{\lambda}_2 = (1+n^{-1} - N^{-1})\hat{S}_p^2 -  \frac{1}{n} \sum_{i \in s} \nabla h(\bf{x}_i^T \hat{\beta})^2 \bf{x}_i^T\left[ \sum_{ j \in s}
\nabla h(\bf{x}_j^T \hat{\beta})\bf{x}_j\bf{x}_j^T\right]^{-1}\bf{x}_i^T \right).
\end{align}
$\tilde{R}_p$ can only be computed using the link function $h$.

A GLM model is fitted with the explanatory variables being the covariate combinations.

```{r}
mod <- "glm"
if(mod == "glm"){m <- glm(Response~COV,data=df,family="binomial")}
if(mod == "cv.glmnet"){m <- cv.glmnet(y=df$Response,x=as.matrix(df[,-c("COV","Response")]),family="binomial",intercept=FALSE,type.measure = "deviance")}
```

No fitted response probabilities from the GLM are $0$.

```{r}
options(scipen=999)
print(c("Minimum response probability"=min(fitted(m))))
```


```{r,message = FALSE}
if(class(m)[1] == "glm"){pred_mat <- data.frame(distinct(df[,c("COV")]))}
if(class(m)[1] == "cv.glmnet"){pred_mat <- as.matrix(distinct(df[,-c("COV","Response")]))}
#Total variation distance
A <- data.frame(COV=distinct(df[,-c("Response")])[,"COV"],P=predict(m,pred_mat,type="response"))
A <- A["P">0,]
G_s <- dim(A)[1]

for(i in 1:(dim(A)[1]-1)){
  if( i == 1){
    a <- abs(as.numeric(unlist(A[1,2])-unlist(A[-1,2])))
    names(a) <- paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+")
    A <- A[-1,]
    
  }else{
    a <- c(a,abs(as.numeric(unlist(A[1,2])-unlist(A[-1,2]))))
    names(a) <- c(names(a)[names(a) != ""],paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+"))
    A <- A[-1,]
  }
}

#R-indicator
if(class(m)[1] == "glm"){
  df_R <- cbind(df,P=predict(m,data.frame(df[,c("COV")]),type="response"))
  beta <- m$coefficients
  mod_mat <- model.matrix(m)
  lin_pred <- (model.matrix(m)) %*% beta
}

if(class(m)[1] == "cv.glmnet"){ 
  df_R <- cbind(df,P=predict(m,as.matrix(df[,-c("COV","Response")]),type="response",s=m$lambda.min))
  colnames(df_R)[ncol(df_R)] <- "P"
  beta <- coef(m,s=m$lambda.min)
  mod_mat <- as.matrix(df[,-c("COV","Response")])
  beta <- beta[,1][-c(which(names(beta[,1]) == "(Intercept)"))]
}

denom <- solve(sum(apply(mod_mat,1,FUN=function(x){as.numeric(exp(x %*% beta)/((1+exp(x %*% beta))^2))*( (x) %*% t(x))})))

S_2 <- (sum(((df_R$P - mean(df_R$Response))^2))/n)

```

In the setting with $n=1000$ and all response probabilities equal to $0.5$ and using GLM's, the representativity measures become:

```{r}
knitr::kable(data.frame(Model=paste(mod),
  V_d=round(1-sum(a)*2/((G_s-1)*G_s),3),
  R_hat=round(1-2*sqrt(S_2),3)), caption="p=0.5",format="markdown")
```


The Lasso model makes subset selection, so the measure $V_d$ is calculated only for the groups which have non-zero coefficients. In a setting with all true response probabilities being equal, then the representativity measure ought to be $100\%$. This is not the case for the GLM model, and it is problematic. Whether or not the Lasso sets coefficients to zero or not (if not, then there is overfitting since it is in theory an intercept model), depends on the $\lambda$ tuning parameter, that is, how much penalization is added to the model fitting.

```{r}
mod <- "cv.glmnet"
if(mod == "glm"){m <- glm(Response~COV,data=df,family="binomial")}
if(mod == "cv.glmnet"){
  
  lambda <- NA
  df_sim <- copy(df)
  for(i in 1:9){
    
    df_sim <- df_sim[,Response := rbinom(n=dim(df_sim)[1],size=1,prob=mean(df$Response))]
    m_sim <- glmnet(y=df_sim$Response,x=as.matrix(dummy_cols(df_sim[,c("COV")])[,-1]),family="binomial",intercept=FALSE,type.measure = "deviance")
    lambda[i] <- m_sim$lambda[max(which(m_sim$df == 0))]
    
  }
  mod_mat <- as.matrix(dummy_cols(df[,c("COV")])[,-1])
  m <- glmnet(y=df$Response,x=mod_mat,family="binomial",intercept=FALSE,type.measure = "deviance",lambda=mean(lambda))
  }




if(mod == "cv.glmnet"){
  sel_cov <- coef(m)
  sel_cov <- sel_cov[,1][-c(which(names(sel_cov[,1]) == "(Intercept)"))]
  sel_cov <- sel_cov[sel_cov!= 0]
  sel_cov_names <- names(sel_cov)
}

if(mod== "glm"){pred_mat <- data.frame(distinct(df[,c("COV")]))}

#This part fails in case of one covariate


#Total variation distance
if(mod == "glm"){
  
  A <- matrix(predict(m,pred_mat,type="response"))
  
  colnames(A) <- "P"
  
  G_s <- dim(A)[1]
  for(i in 1:(dim(A)[1]-1)){
    if( i == 1){
      
      a <- abs(as.numeric(unlist(A[1])-unlist(A[-1])))
      #names(a) <- paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+")
      A <- A[-1]
      
    }else{
      a <- c(a,abs(as.numeric(unlist(A[1])-unlist(A[-1]))))
      #names(a) <- c(names(a)[names(a) != ""],paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+"))
      A <- A[-1]
    }
  }
  1-sum(a)*2/((G_s-1)*G_s) 
}

if(mod == "cv.glmnet")
{
  #if(length(sel_cov) == 1)
  # temp_pred_mat <- c(pred_mat,apply(temp_df,c(1,2),function(x){x <- 0})[1,])
  # names(temp_pred_mat)[1] <- row.names(pred_mat)
  # pred_mat <- temp_pred_mat
  # pred_mat <- pred_mat[names(pred_mat)[match(colnames(mod_mat),names(pred_mat))]]
  
  if(length(sel_cov)>1){
  pred_mat <- as.matrix(mod_mat[1:length(sel_cov_names),sel_cov_names])
  
  diag(pred_mat) <- 1
  temp_df <- mod_mat[,-which(colnames(mod_mat) %in% sel_cov_names)]
  
  pred_mat <- cbind(pred_mat,apply(temp_df,c(1,2),function(x){x <- 0})[1:nrow(pred_mat),])
  
  pred_mat <- pred_mat[,colnames(pred_mat)[match(colnames(mod_mat),colnames(pred_mat))]]

  A <- matrix(predict(m,pred_mat,type="response"))
  
  colnames(A) <- "P"
  
  G_s <- dim(A)[1]
  
  for(i in 1:(dim(A)[1]-1)){
    if(i == 1){
      
      a <- abs(as.numeric(unlist(A[1])-unlist(A[-1])))
      #names(a) <- paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+")
      A <- A[-1]
      
    }else{
      a <- c(a,abs(as.numeric(unlist(A[1])-unlist(A[-1]))))
      #names(a) <- c(names(a)[names(a) != ""],paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+"))
      A <- A[-1]
    }
  }
}else{
  a <- 0
  G_s <- 2
}}

#R-indicator
if(mod == "glm"){
  predict(m,data.frame(df[,c("COV")]),type="response")
  
  df_R <- cbind(df,P=predict(m,data.frame(df[,c("COV")]),type="response"))
  beta <- m$coefficients
  lin_pred <- (model.matrix(m)) %*% beta
  S_2 <- (sum(((df_R$P - mean(df_R$Response))^2))/n)
}

if(mod == "cv.glmnet"){
  
  
  df_R <- cbind(df,P=predict(m,mod_mat,type="response"))
  
  colnames(df_R)[ncol(df_R)] <- "P"
  beta <- coef(m)
  x <- mod_mat
  beta <- beta[,1][-c(which(names(beta[,1]) == "(Intercept)"))]
  
  
  S_2 <- ifelse(length(sel_cov)>1,(sum(((df_R$P - mean(df_R$Response))^2))/n),1)
}



#denom <- solve(sum(apply(x,1,FUN=function(x){as.numeric(exp(x %*% beta)/((1+exp(x %*% beta))^2))*( (x) %*% t(x))})))




data.frame(n=n,
  Model=paste(mod),
  V_d=1-sum(a)*2/((G_s-1)*G_s),
  R_hat=ifelse(S_2==1,1,1-2*sqrt(S_2)))

knitr::kable(data.frame(n=n,
  Model=paste(mod),
  V_d=1-sum(a)*2/((G_s-1)*G_s),
  R_hat=ifelse(S_2==1,1,1-2*sqrt(S_2))), caption="p=0.5",format="markdown")
```

The Lasso can see that there is no need for coefficient apart from the intercept, and thus the representativity is $100\%$.


The tuning parameters in the above settings are: **sample size $n$, the 'true' response probabilities and also which model to use (GLM or Lasso)**. Creating a function from the above code lets us examine the representativity measures when changing the tuning parameters.

```{r}
representativity_simulation <- function(n,mod,p){

men <- matrix(NA,nrow=6,ncol=6)
men[1,] <- c("","Education","","","","")
men[,1] <- c("","Heart Disease","HF","IHD","VHD","AF")
men[2,2:ncol(men)] <- c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")
men[3:nrow(men),2:ncol(men)] <- matrix(c(c(5.7,1.5,9.5,2.4,0.4),
                                         c(7.5,1.9,12,4.5,0.7),
                                         c(1.7,0.6,3,1.2,0.1),
                                         c(3.2,2,7.1,2.9,0.2)),ncol=5,nrow=4,byrow=TRUE)

men <- data.frame(men)
colnames(men) <- colnames(c(rep("",6)))
men[1,1] <- "Men"

women <- matrix(NA,nrow=6,ncol=6)
women[1,] <- c("","Education","","","","")
women[,1] <- c("","Heart Disease","HF","IHD","VHD","AF")
women[2,2:ncol(women)] <- c("Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")
women[3:nrow(men),2:ncol(women)] <- matrix(c(c(3.4,0.3,2.7,1.1,0.2),
                                             c(4.1,0.2,3.9,1.9,0.2),
                                             c(1.7,0.1,1.4,0.8,0.1),
                                             c(3.4,0.4,3.7,2.2,0.1)),ncol=5,nrow=4,byrow=TRUE)

women <- data.frame(women)
colnames(women) <- colnames(c(rep("",6)))
women[1,1] <- "Women"


#n <- 5000

df <- data.frame(matrix(0,nrow=n,ncol=11))
setDT(df)
colnames(df) <- c("Male","Female","HF","IHD","VHD","AF","Basic education","Postgraduate education","Secondary education","Tertiary education","Unknown education")

#Assign half of the records as male and female
#colnames(df) <- c("Sex","Heart Disease")
men <- data.frame(men[-1,])
women <- data.frame(women[-1,])

round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Basic education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Secondary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Basic education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Secondary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Basic education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Secondary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Basic education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Secondary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Basic education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Secondary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Basic education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Secondary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Basic education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Secondary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Unknown education")])/100)+
  
  round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Basic education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Postgraduate education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Secondary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Tertiary education")])/100)+
  round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Unknown education")])/100)


ind <- 
  cumsum(c(round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "HF"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "IHD"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "VHD"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Basic education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Secondary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Tertiary education")])/100),
           round(n*as.numeric(men[which(men[,1] == "AF"),which(men[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "HF"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "IHD"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "VHD"),which(women[1,] == "Unknown education")])/100),
           
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Basic education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Postgraduate education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Secondary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Tertiary education")])/100),
           round(n*as.numeric(women[which(women[,1] == "AF"),which(women[1,] == "Unknown education")])/100)))


df[1:ind[1],c("Male","HF","Basic education")] <- 1
df[(ind[1]+1):ind[2],c("Male","HF","Postgraduate education")] <- 1
df[(ind[2]+1):ind[3],c("Male","HF","Secondary education")] <- 1
df[(ind[3]+1):ind[4],c("Male","HF","Tertiary education")] <- 1
df[(ind[4]+1):ind[5],c("Male","HF","Unknown education")] <- 1

df[(ind[5]+1):ind[6],c("Male","IHD","Basic education")] <- 1
df[(ind[6]+1):ind[7],c("Male","IHD","Postgraduate education")] <- 1
df[(ind[7]+1):ind[8],c("Male","IHD","Secondary education")] <- 1
df[(ind[8]+1):ind[9],c("Male","IHD","Tertiary education")] <- 1
df[(ind[9]+1):ind[10],c("Male","IHD","Unknown education")] <- 1

df[(ind[10]+1):ind[11],c("Male","VHD","Basic education")] <- 1
df[(ind[11]+1):ind[12],c("Male","VHD","Postgraduate education")] <- 1
df[(ind[12]+1):ind[13],c("Male","VHD","Secondary education")] <- 1
df[(ind[13]+1):ind[14],c("Male","VHD","Tertiary education")] <- 1
df[(ind[14]+1):ind[15],c("Male","VHD","Unknown education")] <- 1

df[(ind[15]+1):ind[16],c("Male","AF","Basic education")] <- 1
df[(ind[16]+1):ind[17],c("Male","AF","Postgraduate education")] <- 1
df[(ind[17]+1):ind[18],c("Male","AF","Secondary education")] <- 1
df[(ind[18]+1):ind[19],c("Male","AF","Tertiary education")] <- 1
df[(ind[19]+1):ind[20],c("Male","AF","Unknown education")] <- 1


df[(ind[20]+1):ind[21],c("Female","HF","Basic education")] <- 1
df[(ind[21]+1):ind[22],c("Female","HF","Postgraduate education")] <- 1
df[(ind[22]+1):ind[23],c("Female","HF","Secondary education")] <- 1
df[(ind[23]+1):ind[24],c("Female","HF","Tertiary education")] <- 1
df[(ind[24]+1):ind[25],c("Female","HF","Unknown education")] <- 1

df[(ind[25]+1):ind[26],c("Female","IHD","Basic education")] <- 1
df[(ind[26]+1):ind[27],c("Female","IHD","Postgraduate education")] <- 1
df[(ind[27]+1):ind[28],c("Female","IHD","Secondary education")] <- 1
df[(ind[28]+1):ind[29],c("Female","IHD","Tertiary education")] <- 1
df[(ind[29]+1):ind[30],c("Female","IHD","Unknown education")] <- 1

df[(ind[30]+1):ind[31],c("Female","VHD","Basic education")] <- 1
df[(ind[31]+1):ind[32],c("Female","VHD","Postgraduate education")] <- 1
df[(ind[32]+1):ind[33],c("Female","VHD","Secondary education")] <- 1
df[(ind[33]+1):ind[34],c("Female","VHD","Tertiary education")] <- 1
df[(ind[34]+1):ind[35],c("Female","VHD","Unknown education")] <- 1

df[(ind[35]+1):ind[36],c("Female","AF","Basic education")] <- 1
df[(ind[36]+1):ind[37],c("Female","AF","Postgraduate education")] <- 1
df[(ind[37]+1):ind[38],c("Female","AF","Secondary education")] <- 1
df[(ind[38]+1):ind[39],c("Female","AF","Tertiary education")] <- 1
df[(ind[39]+1):ind[40],c("Female","AF","Unknown education")] <- 1



df$Response <- 0
# 
# p <- c(rep(0.5,20),rep(0.5,20))
df[1:ind[1],"Response"] <- rbinom(ind[1],1,p[1]) #1
df[(ind[1]+1):ind[2],"Response"] <- rbinom(ind[2]-ind[1],1,p[2]) #2
df[(ind[2]+1):ind[3],"Response"] <- rbinom(ind[3]-ind[2],1,p[3]) #3
df[(ind[3]+1):ind[4],"Response"] <- rbinom(ind[4]-ind[3],1,p[4]) #4
df[(ind[4]+1):ind[5],"Response"] <- rbinom(ind[5]-ind[4],1,p[5]) #5
 
df[(ind[5]+1):ind[6],"Response"] <- rbinom(ind[6]-ind[5],1,p[6]) #6
df[(ind[6]+1):ind[7],"Response"] <- rbinom(ind[7]-ind[6],1,p[7]) #7
df[(ind[7]+1):ind[8],"Response"] <- rbinom(ind[8]-ind[7],1,p[8]) #8
df[(ind[8]+1):ind[9],"Response"] <- rbinom(ind[9]-ind[8],1,p[9]) #9
df[(ind[9]+1):ind[10],"Response"] <- rbinom(ind[10]-ind[9],1,p[10]) #10

df[(ind[10]+1):ind[11],"Response"] <- rbinom(ind[11]-ind[10],1,p[11]) #11
df[(ind[11]+1):ind[12],"Response"] <- rbinom(ind[12]-ind[11],1,p[12]) #12
df[(ind[12]+1):ind[13],"Response"] <- rbinom(ind[13]-ind[12],1,p[13]) #13
df[(ind[13]+1):ind[14],"Response"] <- rbinom(ind[14]-ind[13],1,p[14]) #14
df[(ind[14]+1):ind[15],"Response"] <- rbinom(ind[15]-ind[14],1,p[15]) #15

df[(ind[15]+1):ind[16],"Response"] <- rbinom(ind[16]-ind[15],1,p[16]) #16
df[(ind[16]+1):ind[17],"Response"] <- rbinom(ind[17]-ind[16],1,p[17]) #17
df[(ind[17]+1):ind[18],"Response"] <- rbinom(ind[18]-ind[17],1,p[18]) #18
df[(ind[18]+1):ind[19],"Response"] <- rbinom(ind[19]-ind[18],1,p[19]) #19
df[(ind[19]+1):ind[20],"Response"] <- rbinom(ind[20]-ind[19],1,p[20]) #20


df[(ind[20]+1):ind[21],"Response"] <- rbinom(ind[21]-ind[20],1,p[21]) #21
df[(ind[21]+1):ind[22],"Response"] <- rbinom(ind[22]-ind[21],1,p[22]) #22
df[(ind[22]+1):ind[23],"Response"] <- rbinom(ind[23]-ind[22],1,p[23]) #23
df[(ind[23]+1):ind[24],"Response"] <- rbinom(ind[24]-ind[23],1,p[24]) #24
df[(ind[24]+1):ind[25],"Response"] <- rbinom(ind[25]-ind[24],1,p[25]) #25

df[(ind[25]+1):ind[26],"Response"] <- rbinom(ind[26]-ind[25],1,p[26]) #26
df[(ind[26]+1):ind[27],"Response"] <- rbinom(ind[27]-ind[26],1,p[27]) #27
df[(ind[27]+1):ind[28],"Response"] <- rbinom(ind[28]-ind[27],1,p[28]) #28
df[(ind[28]+1):ind[29],"Response"] <- rbinom(ind[29]-ind[28],1,p[29]) #29
df[(ind[29]+1):ind[30],"Response"] <- rbinom(ind[30]-ind[29],1,p[30]) #30

df[(ind[30]+1):ind[31],"Response"] <- rbinom(ind[31]-ind[30],1,p[31]) #31
df[(ind[31]+1):ind[32],"Response"] <- rbinom(ind[32]-ind[31],1,p[32]) #32
df[(ind[32]+1):ind[33],"Response"] <- rbinom(ind[33]-ind[32],1,p[33]) #33
df[(ind[33]+1):ind[34],"Response"] <- rbinom(ind[34]-ind[33],1,p[34]) #34
df[(ind[34]+1):ind[35],"Response"] <- rbinom(ind[35]-ind[34],1,p[35]) #35

df[(ind[35]+1):ind[36],"Response"] <- rbinom(ind[36]-ind[35],1,p[36]) #36
df[(ind[36]+1):ind[37],"Response"] <- rbinom(ind[37]-ind[36],1,p[37]) #37
df[(ind[37]+1):ind[38],"Response"] <- rbinom(ind[38]-ind[37],1,p[38]) #38
df[(ind[38]+1):ind[39],"Response"] <- rbinom(ind[39]-ind[38],1,p[39]) #39
df[(ind[39]+1):ind[40],"Response"] <- rbinom(ind[40]-ind[39],1,p[40]) #40


df$COV <- NA
df$COV[which(apply(df[,c("Male","HF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","HF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","HF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","HF","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","IHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","IHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","IHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","VHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","VHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","VHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Male","AF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Male","AF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Male","AF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Male","AF","Unknown education"),collapse="_")



df$COV[which(apply(df[,c("Female","HF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","HF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","HF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","HF","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","IHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","IHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","IHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","VHD","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","VHD","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","VHD","Unknown education"),collapse="_")

df$COV[which(apply(df[,c("Female","AF","Basic education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Basic education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Postgraduate education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Postgraduate education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Secondary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Secondary education"),collapse="_")
df$COV[which(apply(df[,c("Female","AF","Tertiary education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Tertiary education") ,collapse="_")
df$COV[which(apply(df[,c("Female","AF","Unknown education")],1,FUN=function(x){x[1]*x[2]*x[3]}) == 1)] <- paste(c("Female","AF","Unknown education"),collapse="_")

#rm(df_sim)



#Find which penalty is chosen in the case of an intercept only model, and use this penalty in the model fitting
if(mod == "glm"){m <- glm(Response~COV,data=df,family="binomial")}
if(mod == "cv.glmnet"){
  
  lambda <- NA
  df_sim <- copy(df)
  for(i in 1:9){
    
    df_sim <- df_sim[,Response := rbinom(n=dim(df_sim)[1],size=1,prob=mean(df$Response))]
    m_sim <- glmnet(y=df_sim$Response,x=as.matrix(dummy_cols(df_sim[,c("COV")])[,-1]),family="binomial",intercept=FALSE,type.measure = "deviance")
    lambda[i] <- m_sim$lambda[max(which(m_sim$df == 0))]
    
  }
  mod_mat <- as.matrix(dummy_cols(df[,c("COV")])[,-1])
  m <- glmnet(y=df$Response,x=mod_mat,family="binomial",intercept=FALSE,type.measure = "deviance",lambda=mean(lambda))
  }




if(mod == "cv.glmnet"){
  sel_cov <- coef(m)
  sel_cov <- sel_cov[,1][-c(which(names(sel_cov[,1]) == "(Intercept)"))]
  sel_cov <- sel_cov[sel_cov!= 0]
  sel_cov_names <- names(sel_cov)
}

if(mod== "glm"){pred_mat <- data.frame(distinct(df[,c("COV")]))}

#This part fails in case of one covariate


#Total variation distance
if(mod == "glm"){
  
  A <- matrix(predict(m,pred_mat,type="response"))
  
  colnames(A) <- "P"
  
  G_s <- dim(A)[1]
  for(i in 1:(dim(A)[1]-1)){
    if( i == 1){
      
      a <- abs(as.numeric(unlist(A[1])-unlist(A[-1])))
      #names(a) <- paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+")
      A <- A[-1]
      
    }else{
      a <- c(a,abs(as.numeric(unlist(A[1])-unlist(A[-1]))))
      #names(a) <- c(names(a)[names(a) != ""],paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+"))
      A <- A[-1]
    }
  }
  1-sum(a)*2/((G_s-1)*G_s) 
}

if(mod == "cv.glmnet")
{
  #if(length(sel_cov) == 1)
  # temp_pred_mat <- c(pred_mat,apply(temp_df,c(1,2),function(x){x <- 0})[1,])
  # names(temp_pred_mat)[1] <- row.names(pred_mat)
  # pred_mat <- temp_pred_mat
  # pred_mat <- pred_mat[names(pred_mat)[match(colnames(mod_mat),names(pred_mat))]]
  
  if(length(sel_cov)>1){
  pred_mat <- as.matrix(mod_mat[1:length(sel_cov_names),sel_cov_names])
  
  diag(pred_mat) <- 1
  temp_df <- mod_mat[,-which(colnames(mod_mat) %in% sel_cov_names)]
  
  pred_mat <- cbind(pred_mat,apply(temp_df,c(1,2),function(x){x <- 0})[1:nrow(pred_mat),])
  
  pred_mat <- pred_mat[,colnames(pred_mat)[match(colnames(mod_mat),colnames(pred_mat))]]

  A <- matrix(predict(m,pred_mat,type="response"))
  
  colnames(A) <- "P"
  
  G_s <- dim(A)[1]
  
  for(i in 1:(dim(A)[1]-1)){
    if(i == 1){
      
      a <- abs(as.numeric(unlist(A[1])-unlist(A[-1])))
      #names(a) <- paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+")
      A <- A[-1]
      
    }else{
      a <- c(a,abs(as.numeric(unlist(A[1])-unlist(A[-1]))))
      #names(a) <- c(names(a)[names(a) != ""],paste(unlist(A[1,1]),unlist(A[-1,1]),sep="+"))
      A <- A[-1]
    }
  }
}else{
  a <- 0
  G_s <- 2
}}

#R-indicator
if(mod == "glm"){
  predict(m,data.frame(df[,c("COV")]),type="response")
  
  df_R <- cbind(df,P=predict(m,data.frame(df[,c("COV")]),type="response"))
  beta <- m$coefficients
  lin_pred <- (model.matrix(m)) %*% beta
  S_2 <- (sum(((df_R$P - mean(df_R$Response))^2))/n)
}

if(mod == "cv.glmnet"){
  
  
  df_R <- cbind(df,P=predict(m,mod_mat,type="response"))
  
  colnames(df_R)[ncol(df_R)] <- "P"
  beta <- coef(m)
  x <- mod_mat
  beta <- beta[,1][-c(which(names(beta[,1]) == "(Intercept)"))]
  
  
  S_2 <- ifelse(length(sel_cov)>1,(sum(((df_R$P - mean(df_R$Response))^2))/n),1)
}



#denom <- solve(sum(apply(x,1,FUN=function(x){as.numeric(exp(x %*% beta)/((1+exp(x %*% beta))^2))*( (x) %*% t(x))})))




data.frame(n=n,
  Model=paste(mod),
  V_d=1-sum(a)*2/((G_s-1)*G_s),
  R_hat=ifelse(S_2==1,1,1-2*sqrt(S_2)))
}
```

Changing only the sample size leads to
```{r}
knitr::kable(rbind(
representativity_simulation(n=1000,mod="glm",p=rep(0.5,40)),
representativity_simulation(n=1000,mod="cv.glmnet",p=rep(0.5,40)),
representativity_simulation(n=5000,mod="glm",p=rep(0.5,40)),
representativity_simulation(n=5000,mod="cv.glmnet",p=rep(0.5,40))),caption="p=0.5",format="markdown")
```


It is interesting to change all the response probabilities to become high or low. For the Lasso model, the R-indicators show incorrect results.
```{r}
knitr::kable(rbind(
representativity_simulation(n=1000,mod="glm",p=rep(0.25,40)),
representativity_simulation(n=1000,mod="cv.glmnet",p=rep(0.25,40)),
representativity_simulation(n=5000,mod="glm",p=rep(0.25,40)),
representativity_simulation(n=5000,mod="cv.glmnet",p=rep(0.25,40))),caption="p=0.25",format="markdown")

knitr::kable(rbind(
representativity_simulation(n=1000,mod="glm",p=rep(0.8,40)),
representativity_simulation(n=1000,mod="cv.glmnet",p=rep(0.8,40)),
representativity_simulation(n=5000,mod="glm",p=rep(0.8,40)),
representativity_simulation(n=5000,mod="cv.glmnet",p=rep(0.8,40))),caption="p=0.8",format="markdown")

```

Now we will vary the response probabilities for the 40 groups. 

The first $20$ groups are male, and then female. The first $5$ groups are male with Heart Failure. The subsequent are males with Ischemic heart disease and so on.

First a simulation is made when males have a true reponse probability of $30\%$ and female have a true response probability of $80\%$.


```{r}
knitr::kable(rbind(
representativity_simulation(n=1000,mod="glm",p=c(rep(0.3,20),rep(0.8,20))),
representativity_simulation(n=1000,mod="cv.glmnet",p=c(rep(0.3,20),rep(0.8,20))),
representativity_simulation(n=5000,mod="glm",p=c(rep(0.3,20),rep(0.8,20))),
representativity_simulation(n=5000,mod="cv.glmnet",p=c(rep(0.3,20),rep(0.8,20)))),caption="p(male)=0.3, p(female)=0.8",format="markdown")
```

Now a simulation study is made where males with heart diseases Heart Failure and Atrial Fibrillation have a response probability of $30\%$, males with Ischemic Heart Disease and Valvular Heart Disease have a response probability of $70\%$, whilst females have the same difference accors heart diseases but have a response probability that is $15\%$ higher.

```{r}
p <- c(rep(0.3,5),
rep(0.7,5),
rep(0.7,5),
rep(0.3,5),
rep(0.3+0.15,5),
rep(0.7+0.15,5),
rep(0.7+0.15,5),
rep(0.3+0.15,5))

knitr::kable(rbind(
representativity_simulation(n=1000,mod="glm",p=p),
representativity_simulation(n=1000,mod="cv.glmnet",p=p),
representativity_simulation(n=10000,mod="glm",p=p),
representativity_simulation(n=10000,mod="cv.glmnet",p=p)),caption="p(male,(HF,AF))=0.3, p(male,(IHD,VHD))=0.7, p(female,(HF,AF))=0.45, p(female,(IHD,VHD))=0.85,",format="markdown")

```


</details>
</details>